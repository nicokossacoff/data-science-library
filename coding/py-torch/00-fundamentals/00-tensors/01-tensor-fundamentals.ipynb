{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d134a765",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T22:11:04.275625Z",
     "start_time": "2025-05-04T22:11:03.240846Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.6.0\n",
      "Is MPS available? True\n",
      "Does MPS exists? True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "print(f'PyTorch version: {torch.__version__}')\n",
    "print(f'Is MPS available? {torch.backends.mps.is_available()}')\n",
    "print(f'Does MPS exists? {torch.backends.mps.is_built()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc324fe8",
   "metadata": {},
   "source": [
    "# Introducción\n",
    "\n",
    "*Las redes neuronales son modelos muy poderosos que nos permiten resolver una gran cantidad de problemas gracias a su capacidad para aprender/extraer patrones de los datos. Por ejemplo, estos modelos se pueden utilizar para detectar tumores en imágenes médicas o para transformar texto en audio.*\n",
    "\n",
    "*Cómo podemos entrenar estos modelos? Con ejemplos. Supongamos que queremos entrenar una red neuronal que distingue entre perros y gatos. Lo primero que necesitamos es juntar muchas imágenes que contengan perros y gatos, y a cada una le tendríamos que agregar una etiqueta que indique si el animal de la imagen es un perro o es un gato. A partir de esta combinación de imágenes y etiquetas, el modelo podrá extraer patrones (i.e., aprender las características más comunes en los datos) que le permitirán discriminar entre las imágenes. Una vez entrenado, comparamos sus predicciones con las etiquetas reales, para luego ajustar sus parámetros con el objetivo de mejorar sus predicciones.*\n",
    "\n",
    "*El problema es que las computadoras, a diferencia de los humanos, solo entienden de números. Entonces, para poder entrenar estos modelos, primero necesitamos transformar nuestros datos (i.e., imágenes, texto, audio, etc) en una estructura númerica que pueda ser interpretada por la computadora.*\n",
    "\n",
    "*PyTorch nos proporciona una estructura de datos, los **tensores**, que nos permiten representar nuestros datos -ya sean imágenes, texto o audio- en números. A diferencia de su significado en matemática, los tensores en PyTorch se refieren a **arrays multidimensionales**, similares a los arrays de NumPy, pero con capacidades adicionales que los hacen especialmente útiles para entrenar modelos de Deep Learning*.\n",
    "\n",
    "<img src=\"attachments/tensors-in-pytorch.png\" width=\"1400\" height=\"600\" style=\"display: block; margin: 0 auto;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40869d4b",
   "metadata": {},
   "source": [
    "## Crear tensores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09544bd1",
   "metadata": {},
   "source": [
    "### Escalares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7328fc33",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T22:11:09.549494Z",
     "start_time": "2025-05-04T22:11:09.525326Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a scalar\n",
    "scalar = torch.tensor(7.0)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924d49cea9c92de7",
   "metadata": {},
   "source": [
    "*Los tensores son arrays n-dimensionales. La dimensionalidad del tensor es equivalente a la cantidad de índices necesarios para obtener un escalar. Dicho esto, un escalar es un tensor de dimensión 0 (porque no tenemos que indexar el tensor para obtenerlo).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "736e540971d83f57",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T22:11:35.092411Z",
     "start_time": "2025-05-04T22:11:35.089331Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e75fb03",
   "metadata": {},
   "source": [
    "*Para extraer el número del tensor podemos utilizar el método `item()`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a20f2a7d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T22:16:17.261647Z",
     "start_time": "2025-05-04T22:16:17.258431Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Escalar: 7.0. Type: <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "# Get a tensor back as an integer or float\n",
    "print(f'Escalar: {scalar.item()}. Type: {type(scalar.item())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604cf8f8",
   "metadata": {},
   "source": [
    "### Vectores\n",
    "\n",
    "*Los vectores son tensores **uni-dimensionales**. Utilizando el atributo `.ndim` podemos ver que el tensor que creamos tiene una única dimensión (porque para obtener un escalar necesitamos un único índice).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "237657da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T22:17:52.641320Z",
     "start_time": "2025-05-04T22:17:52.636868Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector = tensor([7, 7])\n",
      "Dimensions: 1\n"
     ]
    }
   ],
   "source": [
    "# Create a vector\n",
    "vector = torch.tensor([7, 7])\n",
    "print(f'Vector = {vector}')\n",
    "print(f'Dimensions: {vector.ndim}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be69fca873dfefe",
   "metadata": {},
   "source": [
    "*Usando el atributo `.shape` podemos ver el tamaño de las dimensiones de nuestro tensor. En este caso, nuestro tensor solo tiene una dimensión con dos elementos.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3646aa57",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T22:19:49.891786Z",
     "start_time": "2025-05-04T22:19:49.888944Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "print(f'Shape: {vector.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2742257f",
   "metadata": {},
   "source": [
    "### Matrices\n",
    "\n",
    "*Las matrices son tensores **bi-dimensionales**, en donde la primera dimensión representa las filas y la segunda dimensión representa las columnas. El tamaño de cada dimensión hace referencia a la cantidad de filas y a la cantidad de columnas de la matriz.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "615852d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T22:21:22.744944Z",
     "start_time": "2025-05-04T22:21:22.741520Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix =\n",
      " tensor([[7, 8],\n",
      "        [8, 9]])\n",
      "Dimensions: 2\n",
      "Shape: torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "MATRIX = torch.tensor([[7, 8], [8, 9]])\n",
    "print(f'Matrix =\\n {MATRIX}')\n",
    "print(f'Dimensions: {MATRIX.ndim}')\n",
    "print(f'Shape: {MATRIX.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce19f8da",
   "metadata": {},
   "source": [
    "### Tensores\n",
    "\n",
    "*Si bien los vectores y las matrices son, al menos en PyTorch, tensores de 1D y 2D, respectivamente, llamamos tensor a los arrays **n-dimensionales** (con $n > 2$). Por ejemplo, debajo tenemos un tensor de tres dimensiones.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e66ad65",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T22:22:07.061843Z",
     "start_time": "2025-05-04T22:22:07.057079Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3],\n",
       "         [4, 5, 6],\n",
       "         [7, 8, 9]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor\n",
    "TENSOR = torch.tensor([[[1, 2, 3],\n",
    "                        [4, 5, 6],\n",
    "                        [7, 8, 9]]])\n",
    "TENSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8506706",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T22:22:19.354754Z",
     "start_time": "2025-05-04T22:22:19.351990Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions: 3\n",
      "Shape: torch.Size([1, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "print(f'Dimensions: {TENSOR.ndim}')\n",
    "print(f'Shape: {TENSOR.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae651728",
   "metadata": {},
   "source": [
    "*Para crear un tensor, utilizando otro(s) tensor(es) como input(s), es necesario utilizar funciones como `torch.stack()` o `torch.vstack()`. La clase `torch.tensor()` solo acepta objetos nativos de Python. En este caso utilizamos la función `torch.stack()` que nos permite concatenar tensores sobre una nueva dimensión.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8480b4ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T22:24:09.477952Z",
     "start_time": "2025-05-04T22:24:09.472232Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of A = 2, Shape of A = torch.Size([3, 3])\n",
      "Dimension of B = 2, Shape of B = torch.Size([3, 3])\n",
      "Dimension of TENSOR = 3, Shape of TENSOR = torch.Size([2, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "A = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "B = torch.tensor([[10, 11, 12], [13, 14, 15], [16, 17, 18]])\n",
    "\n",
    "TENSOR = torch.stack([A, B])\n",
    "\n",
    "print(f'Dimension of A = {A.ndim}, Shape of A = {A.shape}')\n",
    "print(f'Dimension of B = {B.ndim}, Shape of B = {B.shape}')\n",
    "print(f'Dimension of TENSOR = {TENSOR.ndim}, Shape of TENSOR = {TENSOR.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "badf4df8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T22:24:24.013459Z",
     "start_time": "2025-05-04T22:24:24.009875Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1,  2,  3],\n",
       "         [ 4,  5,  6],\n",
       "         [ 7,  8,  9]],\n",
       "\n",
       "        [[10, 11, 12],\n",
       "         [13, 14, 15],\n",
       "         [16, 17, 18]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fae490aa057df1",
   "metadata": {},
   "source": [
    "## Tensores en memoria"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295677d0c032129a",
   "metadata": {},
   "source": [
    "*A diferencia de las estructuras de datos nativas de Python, como las listas, los tensores se guardan en memoria como un **único bloque contiguo**. Qué quiere decir esto? Que a diferencia de las listas, donde cada elemento es un objeto de Python que tiene su propio espacio en memoria, los tensores se encuentran guardados en un único espacio en memoria. Es decir, no importa cuantas dimensiones tenga nuestro tensor, en memoria se guarda como un vector uni-dimensional donde cada elemento se encuentra uno al lado del otro. Esto hace que sea mucho más rápido acceder secuencialmente a los elementos en un tensor y que sea mucho más sencillo vectorizar operaciones con ellos.*\n",
    "\n",
    "*Esto está relacionado con la arquitectura de PyTorch. Cuando creamos una instancia de `torch.Tensor` también creamos una instancia de `torch.Storage`. Esta instancia de `torch.Storage` no es más que un vector uni-dimensional que contiene los datos en memoria. La instancia de `torch.Tensor`, que es con la que nosotros, los usuarios, interactuamos, es una vista de la instancia `torch.Storage`, es decir, una vista de los datos en memoria. Esto hace que PyTorch sea muy eficiente en el manejo de los datos, porque nos permite crear varios tensores sin tener que duplicar nuestros datos en memoria (i.e., solo necesitamos crear una nueva referencia al objeto en memoria).*\n",
    "\n",
    "*La siguiente imagen es muy representación de como se guarda en memoria una lista (u otros objetos nativos de Python) y como se guardan los tensores:*\n",
    "<figure>\n",
    "    <img src=\"attachments/tensors-in-memory.png\" width=\"1400\" height=\"600\" align=\"center\" style=\"display: block; margin: 0 auto;\"/>\n",
    "    <figcaption style=\"text-align: center;\">Stevens, Eli. (2020). Python object (boxed) numeric values versus tensor (unboxed array) numeric values. In Stevens, Eli, <i>Deep Learning with PyTorch</i> (p. 44).</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af764ede7c8b8698",
   "metadata": {},
   "source": [
    "### Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3196e3431d149c",
   "metadata": {},
   "source": [
    "*Como ya dijimos, los tensores se guardan en memoria como vectores uni-dimensionales, aunque los hayamos creado con más de una dimensión. Para poder ver los tensores con las dimensiones deseadas, el objeto `torch.Tensor` contiene varios atributos importantes:*\n",
    "- *`size`. Nos dice cuantos elementos tiene el tensor en cada dimensión.*\n",
    "- *`stride`. Nos dice cuantos elementos en memoria tenemos que movernos para obtener el siguiente elemento de una dimensión. Por ejemplo, en la imagen de abajo podemos ver que para obtener el siguiente elemento en la segunda dimensión (columnas) tenemos que movernos un lugar en memoria, y para obtener el siguiente elemento en la primera dimensión (filas) tenemos que movernos tres lugares en memoria.*\n",
    "- *`offset`. Nos dice cuál es el primer elemento del tensor en la memoria.*\n",
    "- *`storage`. Nos dice donde se encuentra guardado el tensor en memoria.*\n",
    "<figure>\n",
    "    <img src=\"attachments/tensor-metadata.png\" width=\"900\" height=\"700\" align=\"center\" style=\"display: block; margin: 0 auto;\"/>\n",
    "    <figcaption style=\"text-align: center;\">Stevens, Eli. (2020). Relationship between tensor offser, size, and stride. In Stevens, Eli, <i>Deep Learning with PyTorch</i> (p. 56).</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5db5963",
   "metadata": {},
   "source": [
    "## Tensores aleatorios\n",
    "\n",
    "*Por qué queremos aprender a generar tensores aleatorios? Porque los pesos de las redes neuronales se inicializan de esta manera. Entonces, al comenzar el entrenamiento de nuestra red neuronal debemos pasarle un tensor que represente los pesos iniciales, el cual tenemos que poder generar de manera aleatoria.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a4f394da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T22:53:30.394736Z",
     "start_time": "2025-05-04T22:53:30.391845Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_tensor =\n",
      " tensor([[0.6386, 0.5047, 0.0468],\n",
      "        [0.9551, 0.8437, 0.5572]])\n"
     ]
    }
   ],
   "source": [
    "# Tensor de dos dimensiones de tamaño (3, 4)\n",
    "random_tensor = torch.rand(size=(2, 3))\n",
    "print(f'random_tensor =\\n {random_tensor}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cbff825a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T22:53:38.854083Z",
     "start_time": "2025-05-04T22:53:38.852300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions: 2\n",
      "Size: torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "print(f'Dimensions: {random_tensor.ndim}')\n",
    "print(f'Size: {random_tensor.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5e49668e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T22:53:47.597911Z",
     "start_time": "2025-05-04T22:53:47.594731Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_tensor =\n",
      " tensor([[[0.2895, 0.8592, 0.3154],\n",
      "         [0.7859, 0.4792, 0.2665]],\n",
      "\n",
      "        [[0.1918, 0.3231, 0.9610],\n",
      "         [0.7503, 0.5626, 0.2700]],\n",
      "\n",
      "        [[0.2092, 0.8292, 0.7639],\n",
      "         [0.6841, 0.6064, 0.9029]],\n",
      "\n",
      "        [[0.4516, 0.9106, 0.9012],\n",
      "         [0.2175, 0.6269, 0.4178]],\n",
      "\n",
      "        [[0.9009, 0.8265, 0.8337],\n",
      "         [0.9213, 0.0376, 0.2380]],\n",
      "\n",
      "        [[0.5426, 0.7731, 0.0437],\n",
      "         [0.2255, 0.9555, 0.9879]],\n",
      "\n",
      "        [[0.6404, 0.5305, 0.2738],\n",
      "         [0.4166, 0.6042, 0.3748]],\n",
      "\n",
      "        [[0.7394, 0.3000, 0.6479],\n",
      "         [0.0416, 0.6007, 0.4241]],\n",
      "\n",
      "        [[0.8982, 0.4961, 0.6603],\n",
      "         [0.4529, 0.2528, 0.1696]],\n",
      "\n",
      "        [[0.5100, 0.7112, 0.9630],\n",
      "         [0.6973, 0.5117, 0.5903]]])\n"
     ]
    }
   ],
   "source": [
    "random_tensor = torch.rand(size=(10, 2, 3))\n",
    "print(f'random_tensor =\\n {random_tensor}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b225fd74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T22:53:58.226303Z",
     "start_time": "2025-05-04T22:53:58.224601Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions: 3\n",
      "Size: torch.Size([10, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "print(f'Dimensions: {random_tensor.ndim}')\n",
    "print(f'Size: {random_tensor.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05029fa",
   "metadata": {},
   "source": [
    "*Las imágenes las vamos a representar como tensores de tres dimensiones, en donde la primera dimensión representa los canales de colores (RGB), mientras que la segunda y tercera dimensión representa la cantidad de píxeles de la imágen. Por ejemplo, si tenemos una imagen a color de 1024x1024 y la convertimos en un tensor, entonces tendríamos un tensor de tres dimensiones con tamaño `torch.Size([3, 1024, 1024])`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "61226c7f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T22:55:00.861854Z",
     "start_time": "2025-05-04T22:55:00.841873Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.4814, 0.0632, 0.9753,  ..., 0.1883, 0.0756, 0.9011],\n",
       "         [0.3321, 0.1456, 0.4719,  ..., 0.8391, 0.7805, 0.9025],\n",
       "         [0.8482, 0.3054, 0.4833,  ..., 0.8161, 0.4669, 0.0689],\n",
       "         ...,\n",
       "         [0.6489, 0.1121, 0.1003,  ..., 0.7453, 0.2007, 0.9964],\n",
       "         [0.2765, 0.6053, 0.9880,  ..., 0.5661, 0.5327, 0.3379],\n",
       "         [0.1350, 0.9351, 0.9738,  ..., 0.9875, 0.6422, 0.8706]],\n",
       "\n",
       "        [[0.3541, 0.7974, 0.2714,  ..., 0.3374, 0.7037, 0.5539],\n",
       "         [0.7805, 0.4649, 0.8135,  ..., 0.0389, 0.6538, 0.3782],\n",
       "         [0.9135, 0.1864, 0.4188,  ..., 0.3658, 0.5919, 0.9976],\n",
       "         ...,\n",
       "         [0.8582, 0.4580, 0.7376,  ..., 0.6061, 0.8997, 0.4062],\n",
       "         [0.8784, 0.2916, 0.4300,  ..., 0.4109, 0.7739, 0.8302],\n",
       "         [0.6331, 0.1060, 0.0243,  ..., 0.3143, 0.0407, 0.0370]],\n",
       "\n",
       "        [[0.2824, 0.8100, 0.5089,  ..., 0.4428, 0.2192, 0.8499],\n",
       "         [0.1997, 0.4274, 0.6938,  ..., 0.2850, 0.7926, 0.9036],\n",
       "         [0.9079, 0.3626, 0.6193,  ..., 0.9576, 0.1364, 0.1978],\n",
       "         ...,\n",
       "         [0.1833, 0.9051, 0.0858,  ..., 0.2803, 0.3018, 0.6405],\n",
       "         [0.5114, 0.4080, 0.4862,  ..., 0.8726, 0.3103, 0.4125],\n",
       "         [0.8540, 0.4906, 0.4830,  ..., 0.5194, 0.8921, 0.8501]]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_image_tensor = torch.rand(size=(3, 1024, 1024))\n",
    "random_image_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f68d5df5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T22:55:11.707707Z",
     "start_time": "2025-05-04T22:55:11.705950Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones: 3\n",
      "Size: torch.Size([3, 1024, 1024])\n"
     ]
    }
   ],
   "source": [
    "print(f'Dimensiones: {random_image_tensor.ndim}')\n",
    "print(f'Size: {random_image_tensor.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b8b08e558b8e53",
   "metadata": {},
   "source": [
    "*Siempre que trabajemos con procesos aleatorios (o pseudo-aleatorios), vamos a observar diferencias en los resultados. Incluso teniendo la misma semilla, puede que un mismo proceso aleatorio genere distintos resultados si lo ejecutamos en distintos dispositivos (i.e., CPU o GPU). Para más información acerca de como trabajar con procesos no-determinísticos en PyTorch, leer la siguiente [documentación](https://pytorch.org/docs/stable/notes/randomness.html).*\n",
    "\n",
    "*Podemos definir una semilla que nos permita reproducir los resultados de un experimento utilizando la función `torch.manual_seed()` (se define la misma semilla para todos los dispositivos). Ahora, ejecutar multiples veces el mismo código nos devuelve el mismo resultado.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9c9dd953aa1bcb2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T22:56:04.022442Z",
     "start_time": "2025-05-04T22:56:04.011146Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random tensor 1: tensor([[0.8823, 0.9150, 0.3829, 0.9593, 0.3904]])\n",
      "Random tensor 2: tensor([[0.6009, 0.2566, 0.7936, 0.9408, 0.1332]])\n",
      "Are the tensors equal? False\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "random_tensor_1 = torch.rand(size=(1, 5))\n",
    "random_tensor_2 = torch.rand(size=(1, 5))\n",
    "\n",
    "print(f'Random tensor 1: {random_tensor_1}')\n",
    "print(f'Random tensor 2: {random_tensor_2}')\n",
    "\n",
    "# We can compare two tensors using the function torch.equal() or the operator ==\n",
    "print(f'Are the tensors equal? {torch.equal(random_tensor_1, random_tensor_2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c5c870d06425d7",
   "metadata": {},
   "source": [
    "*Notar que, a pesar de estar utilizando la misma semilla, los tensores que generamos no son iguales entre sí. Para obtener dos tensores iguales deberíamos a ejecutar `torch.manual_seed()` antes de crear cada uno de los tensores.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "55962d6e86c71698",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T22:56:40.933172Z",
     "start_time": "2025-05-04T22:56:40.927012Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random tensor 1: tensor([[0.8823, 0.9150, 0.3829, 0.9593, 0.3904]])\n",
      "Random tensor 2: tensor([[0.8823, 0.9150, 0.3829, 0.9593, 0.3904]])\n",
      "Are the tensors equal? True\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42) # Definimos la semilla para el primer tensor\n",
    "random_tensor_1 = torch.rand(size=(1, 5))\n",
    "torch.manual_seed(42) # Definimos la semilla para el segundo tensor\n",
    "random_tensor_2 = torch.rand(size=(1, 5))\n",
    "\n",
    "print(f'Random tensor 1: {random_tensor_1}')\n",
    "print(f'Random tensor 2: {random_tensor_2}')\n",
    "\n",
    "# We can compare two tensors using the function torch.equal() or the operator ==\n",
    "print(f'Are the tensors equal? {torch.equal(random_tensor_1, random_tensor_2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13f1a17",
   "metadata": {},
   "source": [
    "## Tensor-like objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4a5c4383",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T22:56:50.242604Z",
     "start_time": "2025-05-04T22:56:50.236978Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0,  36,  72, 108, 144, 180, 216, 252, 288, 324, 360, 396, 432, 468,\n",
       "        504, 540, 576, 612, 648, 684, 720, 756, 792, 828, 864, 900, 936, 972])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range_tensor = torch.arange(start=0, end=1000, step=36)\n",
    "range_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "00d6d2dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T22:56:52.963045Z",
     "start_time": "2025-05-04T22:56:52.960151Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension: 1\n",
      "Shape: torch.Size([28])\n",
      "Dtype: torch.int64\n"
     ]
    }
   ],
   "source": [
    "print(f'Dimension: {range_tensor.ndim}')\n",
    "print(f'Shape: {range_tensor.shape}')\n",
    "print(f'Dtype: {range_tensor.dtype}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97fc86a",
   "metadata": {},
   "source": [
    "*Cuando decimos que vamos a crear o que creamos un objeto que es \"tensor-like\", nos referimos a crear un nuevo tensor que tenga la misma dimensión, tamaño y tipo de dato que otro tensor ya existente, pero con otros valores.*\n",
    "\n",
    "*Por ejemplo, podemos creamos un nuevo tensor a partir del tensor `range_tensor` que tenga la misma dimensión, tamaño y tipo de dato, pero que la información que contiene sea distinta (solo tenga ceros).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3f911467",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T22:57:22.741123Z",
     "start_time": "2025-05-04T22:57:22.735748Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros = torch.zeros_like(input=range_tensor)\n",
    "zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b77d1008",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T22:57:24.779021Z",
     "start_time": "2025-05-04T22:57:24.776212Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension: 1\n",
      "Shape: torch.Size([28])\n",
      "Dtype: torch.int64\n"
     ]
    }
   ],
   "source": [
    "print(f'Dimension: {zeros.ndim}')\n",
    "print(f'Shape: {zeros.shape}')\n",
    "print(f'Dtype: {zeros.dtype}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33743e580e9500f6",
   "metadata": {},
   "source": [
    "## Atributos de los tensores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2316776f6719ea1a",
   "metadata": {},
   "source": [
    "### Tipo de dato"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67031bba",
   "metadata": {},
   "source": [
    "*Por defecto, PyTorch crea los tensores utilizando el tipo de dato `torch.float32`. Hay muchos más tipos de datos [disponibles](https://pytorch.org/docs/stable/tensors.html#data-types), que se diferencian principalmente por la precisión númerica que nos aportan. Por ejemplo, el tipo de dato `torch.float64` tiene mucho más precisión numérica que el tipo de dato `torch.float32` (casi el doble), pero consume mucho más memoria.*\n",
    "\n",
    "*Podemos especificar el tipo de dato que queremos para nuestro tensor utilizando el argumento `dtype`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cfbd0c5152e47f36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T22:58:57.076837Z",
     "start_time": "2025-05-04T22:58:57.072572Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 2., 1.], dtype=torch.float64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR_0 = torch.tensor([3., 2., 1.], dtype=torch.float64)\n",
    "TENSOR_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "45843e9f473bafb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T22:58:59.700206Z",
     "start_time": "2025-05-04T22:58:59.696680Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR_0.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207eed92c6d856b6",
   "metadata": {},
   "source": [
    "*Podemos modificar el tipo de dato utilizando el método `torch.Tensor.type()` o el método `torch.Tensor.to()`. Este último método es el más recomendado, ya que también nos permite modificar otros atributos del tensor.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4a35ed321e5f5eec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T23:05:07.778888Z",
     "start_time": "2025-05-04T23:05:07.774382Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 2., 1.], dtype=torch.float16)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change tensor's datatype\n",
    "TENSOR_1 = TENSOR_0.to(dtype=torch.float16) # or use torch.Tensor.to()\n",
    "TENSOR_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea516daba2733c9",
   "metadata": {},
   "source": [
    "*Cuando realizamos operaciones matemáticas entre dos tensores con distintos tipos de datos, PyTorch utiliza una **regla de promoción** para definir el tipo de dato del tensor resultante (tendrá el tipo de dato con mayor precisión). Por ejemplo, si multiplicamos un tensor con tipo de dato `torch.float32` y otro con tipo de dato `torch.float64`, el tensor que obtenemos después de la operación es `torch.float64`.*\n",
    "\n",
    "*Esto es algo importante a tener en cuenta porque:*\n",
    "1. *Podemos llegar a consumir más memoria de la esperada si las operaciones que realizamos están constantemente incrementando la precisión númerica de nuestros tensores.*\n",
    "2. *Las operaciones entre tensores con distintos tipos de datos suelen ser menos performantes porque PyTorch también se tiene que encargar de convertir los datos.*\n",
    "3. *Algunos dispositivos tienen soporte limitado para algunos tipos de datos (e.g., las GPU no soportan tensores con tipos de datos `torch.float64` o las `mps` no soportan los tensores con tipos de datos `torch.float16`).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "125494bc90c63117",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T23:05:08.936692Z",
     "start_time": "2025-05-04T23:05:08.931977Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9., 4., 1.], dtype=torch.float64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR_0 * TENSOR_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ba96f0fa9bfdbf",
   "metadata": {},
   "source": [
    "### Dispositivo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e63427",
   "metadata": {},
   "source": [
    "*Podemos también definir el **dispositivo** en donde se guarda y ejecuta el tensor. Hay varios tipos de dispositivos que podemos utilizar, pero los más utilizados son:*\n",
    "1. *`cpu`: nos permite guardar y ejecutar los tensores en la memoria RAM de nuestra computadora o máquina virtual.*\n",
    "2. *`cuda`: nos permite guardar y ejecutar los tensores en la GPU. Si tenemos disponibles más de una GPU, podemos especificar cual queremos utilizar, e.g.,  `cuda:0` (primer GPU), `cuda:1` (segunda GPU), `cuda:2` (tercera GPU), etc.*\n",
    "3. *`mps`: nos permite utilizar la GPU integrada en las computadoras con Apple Silicon (similar a como `cuda` nos permite utilizar las GPUs de NVIDIA). Para más información sobre el uso de MPS con PyTorch, leer la siguiente [documentación](https://pytorch.org/docs/stable/notes/mps.html).*\n",
    "\n",
    "*Por qué es importante definir el dispositivo?:*\n",
    "1. *Si tenemos dos tensores que están guardados en dos dispositivos distintos no podemos realizar operaciones entre ellos.*\n",
    "2. *Mover tensores de un dispositivo a otro puede ser computacionalmente costoso.*\n",
    "3. *El tipo de dato que tengamos disponible para utilizar depende del dispositivo que utilicemos.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "65c0aaf5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T23:08:51.728856Z",
     "start_time": "2025-05-04T23:08:51.723629Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ae0318",
   "metadata": {},
   "source": [
    "*Podemos elegir el dispositivo en donde queremos guardar y ejecutar el tensor al momento de crearlo:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d6e619b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T23:09:26.883761Z",
     "start_time": "2025-05-04T23:09:26.874750Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor: tensor([[[0.2137, 0.1287, 0.7578,  ..., 0.5280, 0.1456, 0.7621],\n",
      "         [0.8253, 0.4947, 0.8110,  ..., 0.7116, 0.7734, 0.5908],\n",
      "         [0.3095, 0.3278, 0.5857,  ..., 0.7197, 0.9459, 0.6801],\n",
      "         ...,\n",
      "         [0.8766, 0.0069, 0.1601,  ..., 0.7396, 0.1457, 0.8224],\n",
      "         [0.9497, 0.4182, 0.1513,  ..., 0.2655, 0.8717, 0.3968],\n",
      "         [0.3618, 0.1220, 0.6681,  ..., 0.9665, 0.2104, 0.3793]],\n",
      "\n",
      "        [[0.5913, 0.7940, 0.0250,  ..., 0.3615, 0.9619, 0.2593],\n",
      "         [0.3742, 0.9553, 0.4215,  ..., 0.9176, 0.5058, 0.0018],\n",
      "         [0.3236, 0.1479, 0.7749,  ..., 0.4080, 0.7298, 0.5154],\n",
      "         ...,\n",
      "         [0.1911, 0.9423, 0.8503,  ..., 0.5304, 0.1596, 0.3789],\n",
      "         [0.2172, 0.7798, 0.9750,  ..., 0.1987, 0.9614, 0.8083],\n",
      "         [0.8856, 0.7259, 0.3923,  ..., 0.7049, 0.5056, 0.8305]],\n",
      "\n",
      "        [[0.7707, 0.6171, 0.6775,  ..., 0.1210, 0.4782, 0.9287],\n",
      "         [0.0903, 0.1733, 0.3913,  ..., 0.9720, 0.0357, 0.6195],\n",
      "         [0.6506, 0.2457, 0.7716,  ..., 0.9107, 0.5576, 0.1392],\n",
      "         ...,\n",
      "         [0.9482, 0.6730, 0.3985,  ..., 0.8227, 0.8427, 0.0947],\n",
      "         [0.3608, 0.9684, 0.7672,  ..., 0.7445, 0.2831, 0.8522],\n",
      "         [0.2800, 0.0937, 0.7143,  ..., 0.1224, 0.1450, 0.0304]]])\n",
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Define a torch.device\n",
    "torch_device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Create a new tensor with specified device\n",
    "TENSOR_2 = torch.rand(size=(3, 1024, 1024), device=torch_device)\n",
    "print(f'Tensor: {TENSOR_2}')\n",
    "print(f'Device: {TENSOR_2.device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b87d709",
   "metadata": {},
   "source": [
    "*Podemos también utilizar la función `torch.Tensor.to` para cambiar el tipo de dato o el dispositivo de un tensor (notar que es necesario re-asignar el tensor a la variable):*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f6d77296c9425c32",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T23:09:41.631193Z",
     "start_time": "2025-05-04T23:09:41.429516Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps:0\n"
     ]
    }
   ],
   "source": [
    "TENSOR_2 = TENSOR_2.to(device='mps')\n",
    "print(f'Device: {TENSOR_2.device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a232e5b62633ef3",
   "metadata": {},
   "source": [
    "### Gradientes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51bdc51199bf470",
   "metadata": {},
   "source": [
    "*Otro argumento importante de los tensores es el argumento `requires_grad`. Cuando definimos `requires_grad=True` en un tensor, le estamos pidiendo a PyTorch que guarde todas las operaciones realizadas sobre ese tensor, para así poder calcular gradientes. Esto es muy útil cuando queremos entrenar un modelo de Deep Learning, ya que nos permite calcular los gradientes de la función de pérdida con respecto a los pesos del modelo utilizando backpropagation.*\n",
    "\n",
    "*Notar que en el siguiente ejemplo creamos una nueva variable, `y`, que es igual a la suma de los elementos en `X`. Luego, para calcular los gradientes de `y` con respecto a los elementos en `X` (i.e., como cambia el valor de `y` ante un cambio infinitesimal en alguno de los elementos de `X`), llamamos a la función `.backward()` desde la variable `y`. Sin embargo, los gradientes los podemos encontrar en el tensor `X` (eso tiene sentido porque los gradientes nos dicen como cambia `y` cuando cambia un elemento de `X`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8d82fb567c1721aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T23:10:48.940725Z",
     "start_time": "2025-05-04T23:10:48.773020Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradients after automatic differentiation: tensor([1., 1., 1.], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "# Creates a tensor and operates on it\n",
    "X = torch.tensor([3., 2., 1.], requires_grad=True, device='mps')\n",
    "\n",
    "# Sum all elements of the tensor and compute the gradients\n",
    "y = X.sum()\n",
    "y.backward()\n",
    "print(f'Gradients after automatic differentiation: {X.grad}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994917e34f947c57",
   "metadata": {},
   "source": [
    "## PyTorch y NumPy\n",
    "\n",
    "*Podemos crear tensores a partir de arrays de NumPy, y viceversa. Esto es muy útil porque podemos utilizar las funcionalidades NumPy para manipular nuestros datos, y luego utilizar los tensores de PyTorch para entrenar nuestros modelos de Deep Learning.*\n",
    "\n",
    "*Podemos crear un tensor a partir de un array de NumPy utilizando la función `torch.from_numpy(ndarray)`. Si queremos convertir un tensor a un array de NumPy, tenemos que utilizar el método `torch.Tensor.numpy()`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9197359ed8de27f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T23:13:12.114081Z",
     "start_time": "2025-05-04T23:13:12.111410Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array de NumPy: \n",
      "[[1. 2. 3.]\n",
      " [4. 5. 6.]\n",
      " [7. 8. 9.]]\n"
     ]
    }
   ],
   "source": [
    "array = np.arange(1., 10.).reshape((3, 3))\n",
    "print(f'Array de NumPy: \\n{array}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e337249c29cd1375",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T23:13:12.746984Z",
     "start_time": "2025-05-04T23:13:12.743206Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor de PyTorch: \n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.],\n",
      "        [7., 8., 9.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.from_numpy(array)\n",
    "print(f'Tensor de PyTorch: \\n{tensor}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1c0471e2713fff",
   "metadata": {},
   "source": [
    "*Algo muy importante a tener en cuenta es que el tipo de dato predeterminado por NumPy es diferente al de PyTorch (NumPy utiliza `float64` mientras que PyTorch utiliza `float32`). El tensor que creamos a partir del array de NumPy hereda el tipo de dato del array, lo cual podría generar problemas al querer operar entre tensores (si los tipos de datos no coinciden).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "55f2bdc051f29607",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T23:13:15.243594Z",
     "start_time": "2025-05-04T23:13:15.241172Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array's datatype: float64\n",
      "Tensor's datatype: torch.float64\n"
     ]
    }
   ],
   "source": [
    "print(f\"Array's datatype: {array.dtype}\")\n",
    "print(f\"Tensor's datatype: {tensor.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9f8e4f7ea8a36f7a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T23:13:16.717111Z",
     "start_time": "2025-05-04T23:13:16.714578Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor's datatype: torch.float32\n"
     ]
    }
   ],
   "source": [
    "tensor = tensor.to(dtype=torch.float32)\n",
    "print(f\"Tensor's datatype: {tensor.dtype}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
