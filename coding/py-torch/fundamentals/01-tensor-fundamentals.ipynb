{
 "cells": [
  {
   "cell_type": "code",
   "id": "d134a765",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T02:45:03.483966Z",
     "start_time": "2025-04-18T02:45:01.873307Z"
    }
   },
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "fc324fe8",
   "metadata": {},
   "source": [
    "# Introducción\n",
    "\n",
    "*Los **tensores** son una de las estructuras de datos más importantes dentro de PyTorch. Son arrays multidimensionales, similares a un `ndarray` de NumPy, pero con capacidades adicionales que los hacen muy útiles para el entrenamiento de modelos de Deep Learning.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40869d4b",
   "metadata": {},
   "source": [
    "## Crear tensores\n",
    "\n",
    "*Por default, PyTorch crea todos los tensores con el tipo de dato `torch.float32`. Sin embargo, hay muchos tipos de datos [disponibles](https://pytorch.org/docs/stable/tensors.html#data-types). Para definir un tipo de dato distinto, podemos utilizar el argumento `dtype` al crear el tensor.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09544bd1",
   "metadata": {},
   "source": [
    "### Escalares"
   ]
  },
  {
   "cell_type": "code",
   "id": "7328fc33",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T02:46:55.646871Z",
     "start_time": "2025-04-18T02:46:55.620934Z"
    }
   },
   "source": [
    "# Create a scalar\n",
    "scalar = torch.tensor(7.0)\n",
    "scalar"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "9e75fb03",
   "metadata": {},
   "source": [
    "*Si quisieramos extraer el número entero de nuestro tensor tendríamos que utilizar el método `item()`.*"
   ]
  },
  {
   "cell_type": "code",
   "id": "a20f2a7d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T02:46:57.896766Z",
     "start_time": "2025-04-18T02:46:57.893782Z"
    }
   },
   "source": [
    "# Get a tensor back as an integer or float\n",
    "print(f'Escalar: {scalar.item()}. Type: {type(scalar.item())}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Escalar: 7.0. Type: <class 'float'>\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "604cf8f8",
   "metadata": {},
   "source": [
    "### Vectores\n",
    "\n",
    "*Los vectores son arrays unidimensionales. Utilizando el atributo `ndim` podemos validar que el tensor que creamos tiene una única dimensión. Podemos mirar con mas detalle las dimensiones del tensor con el atributo `shape` (notar que su dimensión tiene tamaño dos).*"
   ]
  },
  {
   "cell_type": "code",
   "id": "237657da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T02:49:43.598106Z",
     "start_time": "2025-04-18T02:49:43.592679Z"
    }
   },
   "source": [
    "# Create a vector\n",
    "vector = torch.tensor([7, 7])\n",
    "vector"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 7])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "1a88f830",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T02:49:45.813194Z",
     "start_time": "2025-04-18T02:49:45.810504Z"
    }
   },
   "source": [
    "# Dimensions\n",
    "print(f'Number of dimensions: {vector.ndim}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of dimensions: 1\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "3646aa57",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T02:49:47.139051Z",
     "start_time": "2025-04-18T02:49:47.135802Z"
    }
   },
   "source": [
    "print(f'Shape: {vector.shape}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: torch.Size([2])\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "2742257f",
   "metadata": {},
   "source": [
    "### Matrices\n",
    "\n",
    "*Las matrices son arrays **bi-dimensionales**, en donde la primera dimensión representa las filas y la segunda dimensión representa las columnas. El tamaño que tienen esas dimensiones hacen referencia la cantidad de filas y la cantidad de columnas de la matriz.*"
   ]
  },
  {
   "cell_type": "code",
   "id": "615852d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T02:51:35.731096Z",
     "start_time": "2025-04-18T02:51:35.725224Z"
    }
   },
   "source": [
    "MATRIX = torch.tensor([[7, 8], [8, 9]])\n",
    "MATRIX"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7, 8],\n",
       "        [8, 9]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "ed34368b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T02:51:42.473211Z",
     "start_time": "2025-04-18T02:51:42.471065Z"
    }
   },
   "source": [
    "print(f'Number of dimensions: {MATRIX.ndim}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of dimensions: 2\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "69ce7748",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T02:51:43.331657Z",
     "start_time": "2025-04-18T02:51:43.328946Z"
    }
   },
   "source": [
    "print(f'Shape: {MATRIX.shape}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: torch.Size([2, 2])\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "ce19f8da",
   "metadata": {},
   "source": [
    "### Tensores\n",
    "\n",
    "*Si bien los vectores y las matrices que vimos anteriormente también pueden ser llamados \"tensores\" (porque esta es la principal estructura de datos en PyTorch), los tensores propiamente dichos son arrays **n-dimensionales**. Por ejemplo, en el código debajo tenemos un tensor de tres dimensiones, aunque se puede extender fácilmente a más dimensiones.*"
   ]
  },
  {
   "cell_type": "code",
   "id": "9e66ad65",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T02:54:17.557201Z",
     "start_time": "2025-04-18T02:54:17.552196Z"
    }
   },
   "source": [
    "# Create a tensor\n",
    "TENSOR = torch.tensor([[[1, 2, 3],\n",
    "                        [4, 5, 6],\n",
    "                        [7, 8, 9]]])\n",
    "TENSOR"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3],\n",
       "         [4, 5, 6],\n",
       "         [7, 8, 9]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "d8506706",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T02:54:19.430428Z",
     "start_time": "2025-04-18T02:54:19.427642Z"
    }
   },
   "source": [
    "print(f'Number of dimensions: {TENSOR.ndim}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of dimensions: 3\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "58c5cf9e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T02:54:20.594751Z",
     "start_time": "2025-04-18T02:54:20.592183Z"
    }
   },
   "source": [
    "print(f'Shape: {TENSOR.shape}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: torch.Size([1, 3, 3])\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "id": "ae651728",
   "metadata": {},
   "source": [
    "*Para crear un tensor a partir de otro(s) tensor(es) como input(s), es necesario utilizar funciones como `stack()` o `vstack()`. Esto es así porque la clase `torch.tensor()` solo acepta objetos nativos de Python.*\n",
    "\n",
    "*En este caso utilizamos la función `stack()` que nos permite concatenar tensores sobre una nueva dimensión. Si el argumento `dim = 0` entonces crea una primera nueva dimensión para concatenar los tensores (en nuestro caso, como tenemos tensores de dos dimensiones, crea una tercera dimensión).*"
   ]
  },
  {
   "cell_type": "code",
   "id": "8480b4ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T02:56:35.786075Z",
     "start_time": "2025-04-18T02:56:35.779753Z"
    }
   },
   "source": [
    "MATRIX_1 = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "MATRIX_2 = torch.tensor([[10, 11, 12], [13, 14, 15], [16, 17, 18]])\n",
    "\n",
    "# The torch.tensor() class expects Python native data types, so in order to create a tensor from two tensors\n",
    "TENSOR = torch.stack([MATRIX_1, MATRIX_2])\n",
    "TENSOR"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1,  2,  3],\n",
       "         [ 4,  5,  6],\n",
       "         [ 7,  8,  9]],\n",
       "\n",
       "        [[10, 11, 12],\n",
       "         [13, 14, 15],\n",
       "         [16, 17, 18]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "6e000780",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T02:56:40.175023Z",
     "start_time": "2025-04-18T02:56:40.172353Z"
    }
   },
   "source": [
    "print(f'Number of dimensions: {TENSOR.ndim}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of dimensions: 3\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "badf4df8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T02:56:41.533964Z",
     "start_time": "2025-04-18T02:56:41.530670Z"
    }
   },
   "source": [
    "print(f'Shape: {TENSOR.shape}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: torch.Size([2, 3, 3])\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "id": "d5db5963",
   "metadata": {},
   "source": [
    "### Tensores aleatorios\n",
    "\n",
    "*Por qué queremos aprender a generar tensores de forma aleatoria? Porque los pesos de las redes neuronales se inicializan de manera aleatoria. Entonces, al comenzar el entrenamiento de nuestra red neuronal debemos pasarle un tensor que represente los pesos iniciales, el cual tenemos que poder generar de manera aleatoria.*"
   ]
  },
  {
   "cell_type": "code",
   "id": "a4f394da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T02:57:00.921586Z",
     "start_time": "2025-04-18T02:57:00.914727Z"
    }
   },
   "source": [
    "# Tensor de dos dimensiones de tamaño (3, 4)\n",
    "random_tensor = torch.rand(size=(2, 3))\n",
    "random_tensor"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9704, 0.4801, 0.2025],\n",
       "        [0.8203, 0.9294, 0.6374]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "cbff825a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T02:57:03.157831Z",
     "start_time": "2025-04-18T02:57:03.156012Z"
    }
   },
   "source": [
    "print(f'Dimensions: {random_tensor.ndim}')\n",
    "print(f'Tamaños: {random_tensor.shape}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions: 2\n",
      "Tamaños: torch.Size([2, 3])\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "id": "5e49668e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T02:57:04.665347Z",
     "start_time": "2025-04-18T02:57:04.660251Z"
    }
   },
   "source": [
    "# Tensor de dos dimensiones de tamaño (3, 4)\n",
    "random_tensor = torch.rand(size=(10, 2, 3))\n",
    "random_tensor"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.2223, 0.7616, 0.5721],\n",
       "         [0.9461, 0.2712, 0.2611]],\n",
       "\n",
       "        [[0.7423, 0.2800, 0.5012],\n",
       "         [0.0531, 0.8662, 0.2918]],\n",
       "\n",
       "        [[0.4599, 0.1180, 0.6111],\n",
       "         [0.6033, 0.8076, 0.2939]],\n",
       "\n",
       "        [[0.7429, 0.4074, 0.8482],\n",
       "         [0.0263, 0.0058, 0.5888]],\n",
       "\n",
       "        [[0.8081, 0.4449, 0.8161],\n",
       "         [0.6445, 0.8842, 0.3213]],\n",
       "\n",
       "        [[0.6095, 0.7087, 0.1721],\n",
       "         [0.2330, 0.0630, 0.8016]],\n",
       "\n",
       "        [[0.9514, 0.5632, 0.6325],\n",
       "         [0.3030, 0.5803, 0.4163]],\n",
       "\n",
       "        [[0.5859, 0.3571, 0.6655],\n",
       "         [0.4124, 0.1630, 0.3478]],\n",
       "\n",
       "        [[0.6879, 0.2945, 0.1724],\n",
       "         [0.8044, 0.7484, 0.5899]],\n",
       "\n",
       "        [[0.2208, 0.5464, 0.5641],\n",
       "         [0.4732, 0.1654, 0.0155]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "id": "b225fd74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T02:57:18.086945Z",
     "start_time": "2025-04-18T02:57:18.084581Z"
    }
   },
   "source": [
    "print(f'Dimensions: {random_tensor.ndim}')\n",
    "print(f'Tamaños: {random_tensor.shape}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions: 3\n",
      "Tamaños: torch.Size([10, 2, 3])\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "id": "f05029fa",
   "metadata": {},
   "source": [
    "*Las imagenes se pueden representar como tensores de tres dimensiones, en donde la primer dimensión representa los canales de colores (RGB) y la segunda y tercer dimensión representa la cantidad de píxeles de la imágen. Por ejemplo, si tenemos una imagen a color de 1024x1024 y la convertimos en un tensor, entonces tendríamos un tensor de tres dimensiones con tamaño `torch.Size([3, 1024, 1024])`.*"
   ]
  },
  {
   "cell_type": "code",
   "id": "61226c7f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T02:57:51.178129Z",
     "start_time": "2025-04-18T02:57:51.151153Z"
    }
   },
   "source": [
    "random_image_tensor = torch.rand(size=(3, 1024, 1024))\n",
    "random_image_tensor"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.3000, 0.8621, 0.2343,  ..., 0.0176, 0.0604, 0.2521],\n",
       "         [0.8843, 0.7365, 0.6601,  ..., 0.6733, 0.5633, 0.8087],\n",
       "         [0.4394, 0.8064, 0.3360,  ..., 0.0966, 0.0052, 0.2685],\n",
       "         ...,\n",
       "         [0.8810, 0.2448, 0.8114,  ..., 0.7054, 0.5087, 0.4212],\n",
       "         [0.8028, 0.9815, 0.8673,  ..., 0.8679, 0.5931, 0.5669],\n",
       "         [0.0585, 0.9454, 0.0104,  ..., 0.7831, 0.6046, 0.3545]],\n",
       "\n",
       "        [[0.4583, 0.6332, 0.5540,  ..., 0.9738, 0.5965, 0.5811],\n",
       "         [0.6091, 0.8477, 0.4484,  ..., 0.2950, 0.0983, 0.6595],\n",
       "         [0.0158, 0.0589, 0.7507,  ..., 0.6091, 0.1694, 0.0061],\n",
       "         ...,\n",
       "         [0.0488, 0.5793, 0.7349,  ..., 0.7093, 0.2071, 0.5944],\n",
       "         [0.8324, 0.0050, 0.6985,  ..., 0.3546, 0.5413, 0.3017],\n",
       "         [0.3302, 0.7142, 0.0639,  ..., 0.6703, 0.0089, 0.1508]],\n",
       "\n",
       "        [[0.9928, 0.4587, 0.9960,  ..., 0.1059, 0.3823, 0.7579],\n",
       "         [0.9704, 0.4953, 0.1673,  ..., 0.9257, 0.3586, 0.0159],\n",
       "         [0.3927, 0.4262, 0.9744,  ..., 0.5333, 0.6658, 0.9368],\n",
       "         ...,\n",
       "         [0.1885, 0.9107, 0.8683,  ..., 0.5112, 0.5882, 0.2930],\n",
       "         [0.3074, 0.5767, 0.3988,  ..., 0.3438, 0.0180, 0.4262],\n",
       "         [0.0498, 0.5184, 0.6583,  ..., 0.8276, 0.7309, 0.8307]]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "id": "f68d5df5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T02:57:57.200391Z",
     "start_time": "2025-04-18T02:57:57.197813Z"
    }
   },
   "source": [
    "print(f'Dimensiones: {random_image_tensor.ndim}')\n",
    "print(f'Shape: {random_image_tensor.shape}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones: 3\n",
      "Shape: torch.Size([3, 1024, 1024])\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "id": "0d079ef4",
   "metadata": {},
   "source": [
    "### Unos y ceros\n",
    "\n",
    "*En algunas ocaciones nos gustaría tener tensores que solo tienen ceros o unos. Los podemos crear con las funciones `torch.zeros()` o `torch.ones()`.*"
   ]
  },
  {
   "cell_type": "code",
   "id": "125cf825",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T02:58:00.200490Z",
     "start_time": "2025-04-18T02:58:00.194965Z"
    }
   },
   "source": [
    "zeros = torch.zeros(size=(2, 3, 4))\n",
    "zeros"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "id": "cafad9ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T02:58:01.042818Z",
     "start_time": "2025-04-18T02:58:01.038483Z"
    }
   },
   "source": [
    "ones = torch.ones(size=(2, 3, 4))\n",
    "ones"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "markdown",
   "id": "a13f1a17",
   "metadata": {},
   "source": [
    "### Tensor-like objects"
   ]
  },
  {
   "cell_type": "code",
   "id": "4a5c4383",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T02:58:04.135351Z",
     "start_time": "2025-04-18T02:58:04.130143Z"
    }
   },
   "source": [
    "range_tensor = torch.arange(start=0, end=1000, step=36)\n",
    "range_tensor"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0,  36,  72, 108, 144, 180, 216, 252, 288, 324, 360, 396, 432, 468,\n",
       "        504, 540, 576, 612, 648, 684, 720, 756, 792, 828, 864, 900, 936, 972])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "id": "00d6d2dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T02:58:06.584425Z",
     "start_time": "2025-04-18T02:58:06.582059Z"
    }
   },
   "source": [
    "print(f'Dimension: {range_tensor.ndim}')\n",
    "print(f'Shape: {range_tensor.shape}')\n",
    "print(f'Dtype: {range_tensor.dtype}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension: 1\n",
      "Shape: torch.Size([28])\n",
      "Dtype: torch.int64\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "markdown",
   "id": "d97fc86a",
   "metadata": {},
   "source": [
    "*Cuando decimos que vamos a crear o que creamos un objeto que es \"tensor-like\", nos referimos a crear un nuevo tensor que tenga la misma dimensión, tamaño y tipo de dato que otro tensor ya existente, pero con otros valores.*\n",
    "\n",
    "*Por ejemplo, podemos creamos un nuevo tensor a partir del tensor `range_tensor` que tenga la misma dimensión, tamaño y tipo de dato, pero que la información que contiene sea distinta (solo tenga ceros).*"
   ]
  },
  {
   "cell_type": "code",
   "id": "3f911467",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T02:58:30.569111Z",
     "start_time": "2025-04-18T02:58:30.564776Z"
    }
   },
   "source": [
    "zeros = torch.zeros_like(input=range_tensor)\n",
    "zeros"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "id": "b77d1008",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T02:58:31.473363Z",
     "start_time": "2025-04-18T02:58:31.470677Z"
    }
   },
   "source": [
    "print(f'Dimension: {zeros.ndim}')\n",
    "print(f'Shape: {zeros.shape}')\n",
    "print(f'Dtype: {zeros.dtype}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension: 1\n",
      "Shape: torch.Size([28])\n",
      "Dtype: torch.int64\n"
     ]
    }
   ],
   "execution_count": 27
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
