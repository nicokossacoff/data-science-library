{
 "cells": [
  {
   "cell_type": "code",
   "id": "d134a765",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T18:18:19.960972Z",
     "start_time": "2025-04-18T18:18:19.958219Z"
    }
   },
   "source": [
    "import torch\n",
    "print(f'PyTorch version: {torch.__version__}')\n",
    "print(f'Is MPS available? {torch.backends.mps.is_available()}')\n",
    "print(f'Does MPS exists? {torch.backends.mps.is_built()}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.6.0\n",
      "Is MPS available? True\n",
      "Does MPS exists? True\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "id": "fc324fe8",
   "metadata": {},
   "source": [
    "# Introducción\n",
    "\n",
    "*Los **tensores** son una de las estructuras de datos más importantes dentro de PyTorch. Son arrays multidimensionales, similares a un `ndarray` de NumPy, pero con capacidades adicionales que los hacen muy útiles para el entrenamiento de modelos de Deep Learning.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40869d4b",
   "metadata": {},
   "source": [
    "## Crear tensores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09544bd1",
   "metadata": {},
   "source": [
    "### Escalares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7328fc33",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T02:46:55.646871Z",
     "start_time": "2025-04-18T02:46:55.620934Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a scalar\n",
    "scalar = torch.tensor(7.0)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e75fb03",
   "metadata": {},
   "source": [
    "*Si quisieramos extraer el número entero de nuestro tensor tendríamos que utilizar el método `item()`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a20f2a7d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T02:46:57.896766Z",
     "start_time": "2025-04-18T02:46:57.893782Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Escalar: 7.0. Type: <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "# Get a tensor back as an integer or float\n",
    "print(f'Escalar: {scalar.item()}. Type: {type(scalar.item())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604cf8f8",
   "metadata": {},
   "source": [
    "### Vectores\n",
    "\n",
    "*Los vectores son arrays unidimensionales. Utilizando el atributo `ndim` podemos validar que el tensor que creamos tiene una única dimensión. Podemos mirar con mas detalle las dimensiones del tensor con el atributo `shape` (notar que su dimensión tiene tamaño dos).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "237657da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T02:49:43.598106Z",
     "start_time": "2025-04-18T02:49:43.592679Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 7])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a vector\n",
    "vector = torch.tensor([7, 7])\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a88f830",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T02:49:45.813194Z",
     "start_time": "2025-04-18T02:49:45.810504Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of dimensions: 1\n"
     ]
    }
   ],
   "source": [
    "# Dimensions\n",
    "print(f'Number of dimensions: {vector.ndim}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3646aa57",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T02:49:47.139051Z",
     "start_time": "2025-04-18T02:49:47.135802Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "print(f'Shape: {vector.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2742257f",
   "metadata": {},
   "source": [
    "### Matrices\n",
    "\n",
    "*Las matrices son arrays **bi-dimensionales**, en donde la primera dimensión representa las filas y la segunda dimensión representa las columnas. El tamaño que tienen esas dimensiones hacen referencia la cantidad de filas y la cantidad de columnas de la matriz.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "615852d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T02:51:35.731096Z",
     "start_time": "2025-04-18T02:51:35.725224Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7, 8],\n",
       "        [8, 9]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX = torch.tensor([[7, 8], [8, 9]])\n",
    "MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed34368b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T02:51:42.473211Z",
     "start_time": "2025-04-18T02:51:42.471065Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of dimensions: 2\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of dimensions: {MATRIX.ndim}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69ce7748",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T02:51:43.331657Z",
     "start_time": "2025-04-18T02:51:43.328946Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "print(f'Shape: {MATRIX.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce19f8da",
   "metadata": {},
   "source": [
    "### Tensores\n",
    "\n",
    "*Si bien los vectores y las matrices que vimos anteriormente también pueden ser llamados \"tensores\" (porque esta es la principal estructura de datos en PyTorch), los tensores propiamente dichos son arrays **n-dimensionales**. Por ejemplo, en el código debajo tenemos un tensor de tres dimensiones, aunque se puede extender fácilmente a más dimensiones.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e66ad65",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T02:54:17.557201Z",
     "start_time": "2025-04-18T02:54:17.552196Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3],\n",
       "         [4, 5, 6],\n",
       "         [7, 8, 9]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor\n",
    "TENSOR = torch.tensor([[[1, 2, 3],\n",
    "                        [4, 5, 6],\n",
    "                        [7, 8, 9]]])\n",
    "TENSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8506706",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T02:54:19.430428Z",
     "start_time": "2025-04-18T02:54:19.427642Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of dimensions: 3\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of dimensions: {TENSOR.ndim}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58c5cf9e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T02:54:20.594751Z",
     "start_time": "2025-04-18T02:54:20.592183Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: torch.Size([1, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "print(f'Shape: {TENSOR.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae651728",
   "metadata": {},
   "source": [
    "*Para crear un tensor a partir de otro(s) tensor(es) como input(s), es necesario utilizar funciones como `stack()` o `vstack()`. Esto es así porque la clase `torch.tensor()` solo acepta objetos nativos de Python.*\n",
    "\n",
    "*En este caso utilizamos la función `stack()` que nos permite concatenar tensores sobre una nueva dimensión. Si el argumento `dim = 0` entonces crea una primera nueva dimensión para concatenar los tensores (en nuestro caso, como tenemos tensores de dos dimensiones, crea una tercera dimensión).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8480b4ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T02:56:35.786075Z",
     "start_time": "2025-04-18T02:56:35.779753Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1,  2,  3],\n",
       "         [ 4,  5,  6],\n",
       "         [ 7,  8,  9]],\n",
       "\n",
       "        [[10, 11, 12],\n",
       "         [13, 14, 15],\n",
       "         [16, 17, 18]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX_1 = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "MATRIX_2 = torch.tensor([[10, 11, 12], [13, 14, 15], [16, 17, 18]])\n",
    "\n",
    "# The torch.tensor() class expects Python native data types, so in order to create a tensor from two tensors\n",
    "TENSOR = torch.stack([MATRIX_1, MATRIX_2])\n",
    "TENSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e000780",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T02:56:40.175023Z",
     "start_time": "2025-04-18T02:56:40.172353Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of dimensions: 3\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of dimensions: {TENSOR.ndim}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "badf4df8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T02:56:41.533964Z",
     "start_time": "2025-04-18T02:56:41.530670Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: torch.Size([2, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "print(f'Shape: {TENSOR.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5db5963",
   "metadata": {},
   "source": [
    "### Tensores aleatorios\n",
    "\n",
    "*Por qué queremos aprender a generar tensores de forma aleatoria? Porque los pesos de las redes neuronales se inicializan de manera aleatoria. Entonces, al comenzar el entrenamiento de nuestra red neuronal debemos pasarle un tensor que represente los pesos iniciales, el cual tenemos que poder generar de manera aleatoria.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a4f394da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T02:57:00.921586Z",
     "start_time": "2025-04-18T02:57:00.914727Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9820, 0.1792, 0.5302],\n",
       "        [0.3143, 0.9677, 0.3722]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor de dos dimensiones de tamaño (3, 4)\n",
    "random_tensor = torch.rand(size=(2, 3))\n",
    "random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cbff825a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T02:57:03.157831Z",
     "start_time": "2025-04-18T02:57:03.156012Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions: 2\n",
      "Tamaños: torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "print(f'Dimensions: {random_tensor.ndim}')\n",
    "print(f'Tamaños: {random_tensor.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5e49668e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T02:57:04.665347Z",
     "start_time": "2025-04-18T02:57:04.660251Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.2588, 0.2084, 0.9781],\n",
       "         [0.3258, 0.2819, 0.5629]],\n",
       "\n",
       "        [[0.4077, 0.2434, 0.9305],\n",
       "         [0.1911, 0.3808, 0.4754]],\n",
       "\n",
       "        [[0.4987, 0.9741, 0.5369],\n",
       "         [0.6891, 0.7910, 0.6819]],\n",
       "\n",
       "        [[0.1176, 0.5191, 0.0440],\n",
       "         [0.1203, 0.3199, 0.0255]],\n",
       "\n",
       "        [[0.9614, 0.4660, 0.3628],\n",
       "         [0.3325, 0.5683, 0.8378]],\n",
       "\n",
       "        [[0.5982, 0.1143, 0.4015],\n",
       "         [0.9410, 0.9701, 0.0583]],\n",
       "\n",
       "        [[0.7335, 0.1181, 0.8162],\n",
       "         [0.0412, 0.9402, 0.4521]],\n",
       "\n",
       "        [[0.1831, 0.6347, 0.4051],\n",
       "         [0.8247, 0.2526, 0.4277]],\n",
       "\n",
       "        [[0.0990, 0.1635, 0.3707],\n",
       "         [0.6705, 0.2528, 0.4427]],\n",
       "\n",
       "        [[0.5400, 0.1594, 0.6117],\n",
       "         [0.0854, 0.3322, 0.8924]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor de dos dimensiones de tamaño (3, 4)\n",
    "random_tensor = torch.rand(size=(10, 2, 3))\n",
    "random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b225fd74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T02:57:18.086945Z",
     "start_time": "2025-04-18T02:57:18.084581Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions: 3\n",
      "Tamaños: torch.Size([10, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "print(f'Dimensions: {random_tensor.ndim}')\n",
    "print(f'Tamaños: {random_tensor.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05029fa",
   "metadata": {},
   "source": [
    "*Las imagenes se pueden representar como tensores de tres dimensiones, en donde la primer dimensión representa los canales de colores (RGB) y la segunda y tercer dimensión representa la cantidad de píxeles de la imágen. Por ejemplo, si tenemos una imagen a color de 1024x1024 y la convertimos en un tensor, entonces tendríamos un tensor de tres dimensiones con tamaño `torch.Size([3, 1024, 1024])`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "61226c7f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T02:57:51.178129Z",
     "start_time": "2025-04-18T02:57:51.151153Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.8925, 0.6278, 0.2613,  ..., 0.4122, 0.0031, 0.0109],\n",
       "         [0.7298, 0.3350, 0.7771,  ..., 0.2389, 0.4367, 0.8209],\n",
       "         [0.6178, 0.8236, 0.1508,  ..., 0.2359, 0.1650, 0.5251],\n",
       "         ...,\n",
       "         [0.9389, 0.7546, 0.8447,  ..., 0.7073, 0.7264, 0.6078],\n",
       "         [0.9003, 0.3145, 0.7920,  ..., 0.9895, 0.6250, 0.9059],\n",
       "         [0.0570, 0.0024, 0.7315,  ..., 0.8897, 0.2080, 0.4780]],\n",
       "\n",
       "        [[0.3806, 0.2466, 0.8097,  ..., 0.5088, 0.3978, 0.2602],\n",
       "         [0.2367, 0.1366, 0.5563,  ..., 0.9141, 0.0696, 0.8193],\n",
       "         [0.2554, 0.8213, 0.7212,  ..., 0.8288, 0.9923, 0.9311],\n",
       "         ...,\n",
       "         [0.1223, 0.1816, 0.2465,  ..., 0.1422, 0.1325, 0.9611],\n",
       "         [0.1939, 0.0018, 0.7103,  ..., 0.4424, 0.0356, 0.4601],\n",
       "         [0.2124, 0.8028, 0.4986,  ..., 0.3108, 0.6996, 0.8184]],\n",
       "\n",
       "        [[0.4243, 0.6175, 0.6683,  ..., 0.4923, 0.3915, 0.5057],\n",
       "         [0.5467, 0.3246, 0.8679,  ..., 0.5577, 0.5031, 0.5486],\n",
       "         [0.2825, 0.4570, 0.7711,  ..., 0.0871, 0.1571, 0.1179],\n",
       "         ...,\n",
       "         [0.0713, 0.7042, 0.2246,  ..., 0.4722, 0.3766, 0.0528],\n",
       "         [0.7151, 0.9367, 0.0987,  ..., 0.2846, 0.0906, 0.9155],\n",
       "         [0.2363, 0.1731, 0.7749,  ..., 0.5477, 0.9986, 0.9339]]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_image_tensor = torch.rand(size=(3, 1024, 1024))\n",
    "random_image_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f68d5df5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T02:57:57.200391Z",
     "start_time": "2025-04-18T02:57:57.197813Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones: 3\n",
      "Shape: torch.Size([3, 1024, 1024])\n"
     ]
    }
   ],
   "source": [
    "print(f'Dimensiones: {random_image_tensor.ndim}')\n",
    "print(f'Shape: {random_image_tensor.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d079ef4",
   "metadata": {},
   "source": [
    "### Unos y ceros\n",
    "\n",
    "*En algunas ocaciones nos gustaría tener tensores que solo tienen ceros o unos. Los podemos crear con las funciones `torch.zeros()` o `torch.ones()`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "125cf825",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T02:58:00.200490Z",
     "start_time": "2025-04-18T02:58:00.194965Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros = torch.zeros(size=(2, 3, 4))\n",
    "zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cafad9ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T02:58:01.042818Z",
     "start_time": "2025-04-18T02:58:01.038483Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones = torch.ones(size=(2, 3, 4))\n",
    "ones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13f1a17",
   "metadata": {},
   "source": [
    "### Tensor-like objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4a5c4383",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T02:58:04.135351Z",
     "start_time": "2025-04-18T02:58:04.130143Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0,  36,  72, 108, 144, 180, 216, 252, 288, 324, 360, 396, 432, 468,\n",
       "        504, 540, 576, 612, 648, 684, 720, 756, 792, 828, 864, 900, 936, 972])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range_tensor = torch.arange(start=0, end=1000, step=36)\n",
    "range_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "00d6d2dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T02:58:06.584425Z",
     "start_time": "2025-04-18T02:58:06.582059Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension: 1\n",
      "Shape: torch.Size([28])\n",
      "Dtype: torch.int64\n"
     ]
    }
   ],
   "source": [
    "print(f'Dimension: {range_tensor.ndim}')\n",
    "print(f'Shape: {range_tensor.shape}')\n",
    "print(f'Dtype: {range_tensor.dtype}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97fc86a",
   "metadata": {},
   "source": [
    "*Cuando decimos que vamos a crear o que creamos un objeto que es \"tensor-like\", nos referimos a crear un nuevo tensor que tenga la misma dimensión, tamaño y tipo de dato que otro tensor ya existente, pero con otros valores.*\n",
    "\n",
    "*Por ejemplo, podemos creamos un nuevo tensor a partir del tensor `range_tensor` que tenga la misma dimensión, tamaño y tipo de dato, pero que la información que contiene sea distinta (solo tenga ceros).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3f911467",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T02:58:30.569111Z",
     "start_time": "2025-04-18T02:58:30.564776Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros = torch.zeros_like(input=range_tensor)\n",
    "zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b77d1008",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T02:58:31.473363Z",
     "start_time": "2025-04-18T02:58:31.470677Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension: 1\n",
      "Shape: torch.Size([28])\n",
      "Dtype: torch.int64\n"
     ]
    }
   ],
   "source": [
    "print(f'Dimension: {zeros.ndim}')\n",
    "print(f'Shape: {zeros.shape}')\n",
    "print(f'Dtype: {zeros.dtype}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67031bba",
   "metadata": {},
   "source": [
    "### Customized tensors\n",
    "\n",
    "*Por default, PyTorch crea los tensores utilizando el tipo de dato `torch.float32`. Sin embargo, hay muchos más tipos de datos [disponibles](https://pytorch.org/docs/stable/tensors.html#data-types), los cuales se diferencian principalmente por la precisión númerica que nos aportan. Por ejemplo, el tipo de dato `torch.float64` tiene mucho más precisión numérica que el tipo de dato `torch.float32` (casi el doble de decimales), pero consume mucho más memoria.*\n",
    "\n",
    "*Podemos cambiar el tipo de dato de nuestro tensor utilizando el argumento `dtype`.*"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T17:57:14.260245Z",
     "start_time": "2025-04-18T17:57:14.253573Z"
    }
   },
   "cell_type": "code",
   "source": [
    "TENSOR_0 = torch.tensor([3., 2., 1.], dtype=torch.float64)\n",
    "TENSOR_0"
   ],
   "id": "cfbd0c5152e47f36",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 2., 1.], dtype=torch.float64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T17:57:14.944863Z",
     "start_time": "2025-04-18T17:57:14.942355Z"
    }
   },
   "cell_type": "code",
   "source": "TENSOR_0.dtype",
   "id": "45843e9f473bafb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T17:57:22.333707Z",
     "start_time": "2025-04-18T17:57:22.330746Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Change tensor's datatype\n",
    "TENSOR_1 = TENSOR_0.type(torch.float16) # or use torch.Tensor.to()\n",
    "TENSOR_1"
   ],
   "id": "4a35ed321e5f5eec",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 2., 1.], dtype=torch.float16)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "*Cuando realizamos operaciones matemáticas entre tensores que fueron definidos con distintos tipos de datos, PyTorch utiliza una **regla de promoción** para definir el tipo de dato que tendrá el tensor resultante (por lo general, tendrá el tipo de dato con mayor precisión). Por ejemplo, si multiplicamos un tensor con tipo de dato `torch.float32` y otro con tipo de dato `torch.float64`, el tensor que obtenemos después de la operación es `torch.float64`.*\n",
    "\n",
    "*Esto es algo importante a tener en cuenta porque:*\n",
    "1. *Podemos llegar a consumir más memoria de la esperada si las operaciones que realizamos están constantemente incrementando la precisión númerica de nuestros tensores.*\n",
    "2. *Las operaciones entre tensores con distintos tipos de datos suelen ser menos performantes porque PyTorch se debe encargar también de convertir los datos.*\n",
    "3. *Algunos dispositivos tienen soporte limitado para algunos tipos de datos (e.g., las GPU no soportan tensores con tipos de datos `torch.float64` o las `mps` no soportan los tensores con tipos de datos `torch.float16`).*"
   ],
   "id": "cea516daba2733c9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T17:58:59.875263Z",
     "start_time": "2025-04-18T17:58:59.871199Z"
    }
   },
   "cell_type": "code",
   "source": "TENSOR_0 * TENSOR_1",
   "id": "125494bc90c63117",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9., 4., 1.], dtype=torch.float64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "id": "f8e63427",
   "metadata": {},
   "source": [
    "*Podemos también definir el **dispositivo** en donde se guarda y ejecuta el tensor. Hay varios tipos de dispositivos que podemos utilizar, pero los más utilizados son:*\n",
    "1. *`cpu`: nos permite guardar y ejecutar los tensores en la memoria RAM de nuestra computadora o máquina virtual.*\n",
    "2. *`cuda`: nos permite guardar y ejecutar los tensores en la GPU. Si tenemos disponibles más de una GPU, podemos especificar cual queremos utilizar, e.g.,  `cuda:0` (primer GPU), `cuda:1` (segunda GPU), `cuda:2` (tercera GPU), etc.*\n",
    "3. *`mps`: nos prmite utilizar la GPU integrada en las computadoras con chips Apple Silicon (similar a como `cuda` nos permite utilizar las GPUs de NVIDIA).*\n",
    "\n",
    "*Por qué es importante definir el dispositivo?:*\n",
    "1. *Si tenemos dos tensores que están guardados en dos dispositivos distintos no podemos realizar operaciones entre ellos.*\n",
    "2. *Si queremos guardar y ejecutar los tensores en la GPU, tenemos que seleccionar el dispositivo `cuda`.*\n",
    "3. *Mover tensores de un dispositivo a otro puede ser computacionalmente costoso.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "65c0aaf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ae0318",
   "metadata": {},
   "source": [
    "*Podemos elegir el dispositivo en donde queremos guardar y ejecutar el tensor al momento de crearlo:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d6e619b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor: tensor([[[0.8056, 0.8615, 0.5046,  ..., 0.4668, 0.6164, 0.5404],\n",
      "         [0.9239, 0.7019, 0.5254,  ..., 0.9522, 0.9213, 0.4076],\n",
      "         [0.1358, 0.5212, 0.0534,  ..., 0.4795, 0.7317, 0.4672],\n",
      "         ...,\n",
      "         [0.5984, 0.7380, 0.7738,  ..., 0.5883, 0.6407, 0.8307],\n",
      "         [0.0475, 0.6639, 0.4176,  ..., 0.7113, 0.8032, 0.8278],\n",
      "         [0.4835, 0.5502, 0.1951,  ..., 0.0073, 0.2049, 0.3122]],\n",
      "\n",
      "        [[0.9995, 0.7859, 0.4808,  ..., 0.6156, 0.6079, 0.5768],\n",
      "         [0.0739, 0.1870, 0.6023,  ..., 0.1718, 0.8409, 0.7399],\n",
      "         [0.8333, 0.6206, 0.5385,  ..., 0.7740, 0.1770, 0.2031],\n",
      "         ...,\n",
      "         [0.7577, 0.6314, 0.8505,  ..., 0.2738, 0.9426, 0.0358],\n",
      "         [0.6079, 0.5930, 0.8151,  ..., 0.3913, 0.6865, 0.9591],\n",
      "         [0.4419, 0.4249, 0.2461,  ..., 0.5989, 0.2518, 0.7804]],\n",
      "\n",
      "        [[0.1224, 0.4576, 0.3832,  ..., 0.1964, 0.1862, 0.6033],\n",
      "         [0.0582, 0.7010, 0.5833,  ..., 0.8393, 0.8065, 0.6335],\n",
      "         [0.3276, 0.5404, 0.9176,  ..., 0.3553, 0.2088, 0.5501],\n",
      "         ...,\n",
      "         [0.3057, 0.6091, 0.0543,  ..., 0.6496, 0.6673, 0.4648],\n",
      "         [0.5657, 0.2269, 0.5099,  ..., 0.5947, 0.7817, 0.7664],\n",
      "         [0.7055, 0.1542, 0.4196,  ..., 0.2304, 0.3524, 0.1985]]])\n",
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Define a torch.device\n",
    "torch_device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Create a new tensor with specified device\n",
    "TENSOR_2 = torch.rand(size=(3, 1024, 1024), device='cpu')\n",
    "print(f'Tensor: {TENSOR_2}')\n",
    "print(f'Device: {TENSOR_2.device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b87d709",
   "metadata": {},
   "source": [
    "*Podemos también utilizar la función `torch.Tensor.to` para cambiar el tipo de dato o el dispositivo de un tensor (notar que es necesario re-asignar el tensor a la variable):*"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "TENSOR_2 = TENSOR_2.to(device='mps')\n",
    "print(f'Device: {TENSOR_2.device}')"
   ],
   "id": "f6d77296c9425c32"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "*Otro argumento muy importante que tienen los tensores en PyTorch es el argumento `requires_grad`. Cuando definimos `requires_grad=True` en un tensor, lo que le estamos pidiendo a PyTorch es que guarde todas las operaciones realizadas sobre un tensor, para así poder calcular los gradientes. Esto es muy útil cuando queremos entrenar un modelo de Deep Learning, ya que nos permite calcular los gradientes de los pesos del modelo de manera automática utilizando backpropagation.*\n",
    "\n",
    "*Notar que en el siguiente ejemplo creamos una nueva variable, `y`, que es igual a la suma de los elementos del tensor `X`. Luego, para calcular los gradientes de `y` con respecto a los elementos en `X`, llamamos a la función `.backward()` desde la variable `y`. Sin embargo, los gradientes los podemos encontrar en el tensor `X` (eso tiene sentido porque los gradientes nos dicen como cambia `y` cuando cambia un elemento de `X`.*"
   ],
   "id": "51bdc51199bf470"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T18:15:03.252821Z",
     "start_time": "2025-04-18T18:15:03.239987Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Creates a tensor and operates on it\n",
    "X = torch.tensor([3., 2., 1.], requires_grad=True, device='mps')\n",
    "\n",
    "# Sum all elements of the tensor and compute the gradients\n",
    "y = X.sum()\n",
    "y.backward()\n",
    "print(f'Gradients after automatic differentiation: {TENSOR_0.grad}')"
   ],
   "id": "8d82fb567c1721aa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradients after automatic differentiation: tensor([1., 1., 1.], device='mps:0')\n"
     ]
    }
   ],
   "execution_count": 13
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
