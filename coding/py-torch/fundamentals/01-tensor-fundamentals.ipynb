{
 "cells": [
  {
   "cell_type": "code",
   "id": "d134a765",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T23:39:44.633324Z",
     "start_time": "2025-04-27T23:39:44.626816Z"
    }
   },
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "print(f'PyTorch version: {torch.__version__}')\n",
    "print(f'Is MPS available? {torch.backends.mps.is_available()}')\n",
    "print(f'Does MPS exists? {torch.backends.mps.is_built()}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.6.0\n",
      "Is MPS available? True\n",
      "Does MPS exists? True\n"
     ]
    }
   ],
   "execution_count": 66
  },
  {
   "cell_type": "markdown",
   "id": "fc324fe8",
   "metadata": {},
   "source": [
    "# Introducción\n",
    "\n",
    "*Las redes neuronales son modelos estadísticos que nos permiten resolver problemas complejos gracias a su capacidad de aprender patrones en los datos. Por ejemplo, podemos utilizar estos modelos para detectar tumores en imágenes médicas o transformar texto en audio.*\n",
    "\n",
    "*La manera que tenemos de entrenar estos modelos es con ejemplos. Por ejemplo, si quisiéramos entrenar un modelo que distinga entre perros y gatos, deberíamos mostrarle imágenes con perros y gatos, comparar las predicciones del modelo con las etiquetas reales (i.e., perro o gato), y luego ajustar el modelo para que sus predicciones se vuelvan más precisas. El problema que tenemos es que las computadoras, a diferencia de los humanos, solo entienden de números. Entonces, para poder entrenar estos modelos, primero necesitamos transformar nuestros datos (i.e., imágenes) en un formato que la computadora pueda entender.*\n",
    "\n",
    "*PyTorch nos proporciona una estructura de datos, los **tensores**, que nos permiten representar nuestros datos en números. A diferencia de su significado en matemática, los tensores en PyTorch se refieren a arrays multidimensionales, similares a los arrays de NumPy, pero con capacidades adicionales que los hacen especialmente útiles para entrenar modelos de Deep Learning*.\n",
    "\n",
    "<img src=\"attachments/tensors-in-pytorch.png\" width=\"900\" height=\"700\" align=\"center\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40869d4b",
   "metadata": {},
   "source": [
    "## Crear tensores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09544bd1",
   "metadata": {},
   "source": [
    "### Escalares"
   ]
  },
  {
   "cell_type": "code",
   "id": "7328fc33",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T23:39:44.658575Z",
     "start_time": "2025-04-27T23:39:44.655770Z"
    }
   },
   "source": [
    "# Create a scalar\n",
    "scalar = torch.tensor(7.0)\n",
    "scalar"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 67
  },
  {
   "cell_type": "markdown",
   "id": "9e75fb03",
   "metadata": {},
   "source": "*Para extraer el número del tensor podemos utilizar el método `item()`.*"
  },
  {
   "cell_type": "code",
   "id": "a20f2a7d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T23:39:44.681346Z",
     "start_time": "2025-04-27T23:39:44.679569Z"
    }
   },
   "source": [
    "# Get a tensor back as an integer or float\n",
    "print(f'Escalar: {scalar.item()}. Type: {type(scalar.item())}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Escalar: 7.0. Type: <class 'float'>\n"
     ]
    }
   ],
   "execution_count": 68
  },
  {
   "cell_type": "markdown",
   "id": "604cf8f8",
   "metadata": {},
   "source": [
    "### Vectores\n",
    "\n",
    "*Los vectores son tensores **unidimensionales**. Utilizando el atributo `ndim` podemos validar que el tensor que creamos tiene una única dimensión. Podemos mirar con más detalle las dimensiones del tensor con el atributo `shape` (notar que su dimensión tiene tamaño dos porque tiene solo dos elementos).*"
   ]
  },
  {
   "cell_type": "code",
   "id": "237657da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T23:39:44.697743Z",
     "start_time": "2025-04-27T23:39:44.695256Z"
    }
   },
   "source": [
    "# Create a vector\n",
    "vector = torch.tensor([7, 7])\n",
    "vector"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 7])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 69
  },
  {
   "cell_type": "code",
   "id": "1a88f830",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T23:39:44.712600Z",
     "start_time": "2025-04-27T23:39:44.710975Z"
    }
   },
   "source": [
    "# Dimensions\n",
    "print(f'Number of dimensions: {vector.ndim}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of dimensions: 1\n"
     ]
    }
   ],
   "execution_count": 70
  },
  {
   "cell_type": "code",
   "id": "3646aa57",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T23:39:44.729152Z",
     "start_time": "2025-04-27T23:39:44.726704Z"
    }
   },
   "source": [
    "print(f'Shape: {vector.shape}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: torch.Size([2])\n"
     ]
    }
   ],
   "execution_count": 71
  },
  {
   "cell_type": "markdown",
   "id": "2742257f",
   "metadata": {},
   "source": [
    "### Matrices\n",
    "\n",
    "*Las matrices son tensores **bi-dimensionales**, en donde la primera dimensión representa las filas y la segunda dimensión representa las columnas. El tamaño que tienen las dimensiones hacen referencia la cantidad de filas y la cantidad de columnas de la matriz.*"
   ]
  },
  {
   "cell_type": "code",
   "id": "615852d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T23:39:44.745319Z",
     "start_time": "2025-04-27T23:39:44.743081Z"
    }
   },
   "source": [
    "MATRIX = torch.tensor([[7, 8], [8, 9]])\n",
    "MATRIX"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7, 8],\n",
       "        [8, 9]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 72
  },
  {
   "cell_type": "code",
   "id": "ed34368b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T23:39:44.776840Z",
     "start_time": "2025-04-27T23:39:44.775011Z"
    }
   },
   "source": [
    "print(f'Number of dimensions: {MATRIX.ndim}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of dimensions: 2\n"
     ]
    }
   ],
   "execution_count": 73
  },
  {
   "cell_type": "code",
   "id": "69ce7748",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T23:39:44.805061Z",
     "start_time": "2025-04-27T23:39:44.803588Z"
    }
   },
   "source": [
    "print(f'Shape: {MATRIX.shape}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: torch.Size([2, 2])\n"
     ]
    }
   ],
   "execution_count": 74
  },
  {
   "cell_type": "markdown",
   "id": "ce19f8da",
   "metadata": {},
   "source": [
    "### Tensores\n",
    "\n",
    "*Si bien los vectores y las matrices son, al menos en PyTorch, tensores de 1D y 2D, respectivamente, llamamos tensor a los arrays **n-dimensionales** (con $n > 0$). Por ejemplo, en el código debajo tenemos un tensor de tres dimensiones.*"
   ]
  },
  {
   "cell_type": "code",
   "id": "9e66ad65",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T23:39:44.823340Z",
     "start_time": "2025-04-27T23:39:44.821091Z"
    }
   },
   "source": [
    "# Create a tensor\n",
    "TENSOR = torch.tensor([[[1, 2, 3],\n",
    "                        [4, 5, 6],\n",
    "                        [7, 8, 9]]])\n",
    "TENSOR"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3],\n",
       "         [4, 5, 6],\n",
       "         [7, 8, 9]]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 75
  },
  {
   "cell_type": "code",
   "id": "d8506706",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T23:39:44.841804Z",
     "start_time": "2025-04-27T23:39:44.840256Z"
    }
   },
   "source": [
    "print(f'Number of dimensions: {TENSOR.ndim}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of dimensions: 3\n"
     ]
    }
   ],
   "execution_count": 76
  },
  {
   "cell_type": "code",
   "id": "58c5cf9e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T23:39:44.859521Z",
     "start_time": "2025-04-27T23:39:44.858002Z"
    }
   },
   "source": [
    "print(f'Shape: {TENSOR.shape}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: torch.Size([1, 3, 3])\n"
     ]
    }
   ],
   "execution_count": 77
  },
  {
   "cell_type": "markdown",
   "id": "ae651728",
   "metadata": {},
   "source": "*Para crear un tensor a partir de otro(s) tensor(es) como input(s), es necesario utilizar funciones como `torch.stack()` o `torch.vstack()`. La clase `torch.tensor()` solo acepta objetos nativos de Python. En este caso utilizamos la función `torch.stack()` que nos permite concatenar tensores sobre una nueva dimensión.*"
  },
  {
   "cell_type": "code",
   "id": "8480b4ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T23:39:44.875779Z",
     "start_time": "2025-04-27T23:39:44.872842Z"
    }
   },
   "source": [
    "MATRIX_1 = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "MATRIX_2 = torch.tensor([[10, 11, 12], [13, 14, 15], [16, 17, 18]])\n",
    "\n",
    "# The torch.tensor() class expects Python native data types, so in order to create a tensor from two tensors\n",
    "TENSOR = torch.stack([MATRIX_1, MATRIX_2])\n",
    "TENSOR"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1,  2,  3],\n",
       "         [ 4,  5,  6],\n",
       "         [ 7,  8,  9]],\n",
       "\n",
       "        [[10, 11, 12],\n",
       "         [13, 14, 15],\n",
       "         [16, 17, 18]]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 78
  },
  {
   "cell_type": "code",
   "id": "6e000780",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T23:39:44.890511Z",
     "start_time": "2025-04-27T23:39:44.888917Z"
    }
   },
   "source": [
    "print(f'Number of dimensions: {TENSOR.ndim}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of dimensions: 3\n"
     ]
    }
   ],
   "execution_count": 79
  },
  {
   "cell_type": "code",
   "id": "badf4df8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T23:39:44.906283Z",
     "start_time": "2025-04-27T23:39:44.904689Z"
    }
   },
   "source": [
    "print(f'Shape: {TENSOR.shape}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: torch.Size([2, 3, 3])\n"
     ]
    }
   ],
   "execution_count": 80
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Tensores en memoria",
   "id": "78fae490aa057df1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "*A diferencia de las estructuras de datos nativas de Python, como las listas, los tensores se guardan en memoria como un bloque contiguo. Qué quiere decir esto? Que a diferencia de las listas, donde cada elemento tiene su propio espacio en memoria, los tensores se encuentran guardados en un único espacio en memoria, donde cada elemento se encuentra uno al lado del otro (no importa cuantas dimensiones tenga nuestro tensor, en memoria siempre se va a guardar como un vector unidimensional). Esto hace que sea mucho más rápido acceder secuencialmente a los elementos de un tensor y que sea mucho más sencillo vectorizar operaciones con ellos.*\n",
    "\n",
    "*La siguiente imagen es muy descriptiva de como se guardan las listas (u otros objetos nativos de Python) y los tensores en memoria:*\n",
    "<img src=\"attachments/tensors-in-memory.png\" width=\"900\" height=\"700\" align=\"center\" />"
   ],
   "id": "295677d0c032129a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Metadata",
   "id": "af764ede7c8b8698"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "*Como ya dijimos, los tensores se guardan de manera contigua en memoria. Para poder acceder a los elementos utilizando los índices, un tensor tiene información adicional que permite definirlos inequívocamente:*\n",
    "- *`size`. Nos dice cuantos elementos tiene el tensor en cada dimensión.*\n",
    "- *`stride`. Nos dice cuantos elementos en memoria tenemos que movernos para obtener el siguiente elemento de una dimensión. Por ejemplo, en la imagen de abajo podemos ver que para obtener el siguiente elemento en la segunda dimensión (columnas) tenemos que movernos un lugar en memoria, y para obtener el siguiente elemento en la primera dimensión (filas) tenemos que movernos tres lugares en memoria.*\n",
    "- *`offset`. Nos dice cuál es el primer elemento del tensor en la memoria.*\n",
    "- *`storage`. Nos dice donde se encuentra guardado el tensor en memoria.*\n",
    "\n",
    "<img src=\"attachments/tensor-metadata.png\" width=\"900\" height=\"700\" align=\"center\" />"
   ],
   "id": "ab3196e3431d149c"
  },
  {
   "cell_type": "markdown",
   "id": "d5db5963",
   "metadata": {},
   "source": [
    "## Tensores aleatorios\n",
    "\n",
    "*Por qué queremos aprender a generar tensores de forma aleatoria? Porque los pesos de las redes neuronales se inicializan es esta manera. Entonces, al comenzar el entrenamiento de nuestra red neuronal debemos pasarle un tensor que represente los pesos iniciales, el cual tenemos que poder generar de manera aleatoria.*"
   ]
  },
  {
   "cell_type": "code",
   "id": "a4f394da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T23:39:44.922378Z",
     "start_time": "2025-04-27T23:39:44.920017Z"
    }
   },
   "source": [
    "# Tensor de dos dimensiones de tamaño (3, 4)\n",
    "random_tensor = torch.rand(size=(2, 3))\n",
    "random_tensor"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6009, 0.2566, 0.7936],\n",
       "        [0.9408, 0.1332, 0.9346]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 81
  },
  {
   "cell_type": "code",
   "id": "cbff825a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T23:39:44.952267Z",
     "start_time": "2025-04-27T23:39:44.950044Z"
    }
   },
   "source": [
    "print(f'Dimensions: {random_tensor.ndim}')\n",
    "print(f'Tamaños: {random_tensor.shape}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions: 2\n",
      "Tamaños: torch.Size([2, 3])\n"
     ]
    }
   ],
   "execution_count": 82
  },
  {
   "cell_type": "code",
   "id": "5e49668e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T23:39:44.979414Z",
     "start_time": "2025-04-27T23:39:44.976718Z"
    }
   },
   "source": [
    "random_tensor = torch.rand(size=(10, 2, 3))\n",
    "random_tensor"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.5936, 0.8694, 0.5677],\n",
       "         [0.7411, 0.4294, 0.8854]],\n",
       "\n",
       "        [[0.5739, 0.2666, 0.6274],\n",
       "         [0.2696, 0.4414, 0.2969]],\n",
       "\n",
       "        [[0.8317, 0.1053, 0.2695],\n",
       "         [0.3588, 0.1994, 0.5472]],\n",
       "\n",
       "        [[0.0062, 0.9516, 0.0753],\n",
       "         [0.8860, 0.5832, 0.3376]],\n",
       "\n",
       "        [[0.8090, 0.5779, 0.9040],\n",
       "         [0.5547, 0.3423, 0.6343]],\n",
       "\n",
       "        [[0.3644, 0.7104, 0.9464],\n",
       "         [0.7890, 0.2814, 0.7886]],\n",
       "\n",
       "        [[0.5895, 0.7539, 0.1952],\n",
       "         [0.0050, 0.3068, 0.1165]],\n",
       "\n",
       "        [[0.9103, 0.6440, 0.7071],\n",
       "         [0.6581, 0.4913, 0.8913]],\n",
       "\n",
       "        [[0.1447, 0.5315, 0.1587],\n",
       "         [0.6542, 0.3278, 0.6532]],\n",
       "\n",
       "        [[0.3958, 0.9147, 0.2036],\n",
       "         [0.2018, 0.2018, 0.9497]]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 83
  },
  {
   "cell_type": "code",
   "id": "b225fd74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T23:39:44.994777Z",
     "start_time": "2025-04-27T23:39:44.992696Z"
    }
   },
   "source": [
    "print(f'Dimensions: {random_tensor.ndim}')\n",
    "print(f'Tamaños: {random_tensor.shape}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions: 3\n",
      "Tamaños: torch.Size([10, 2, 3])\n"
     ]
    }
   ],
   "execution_count": 84
  },
  {
   "cell_type": "markdown",
   "id": "f05029fa",
   "metadata": {},
   "source": [
    "*Las imagenes se pueden representar como tensores de tres dimensiones, en donde la primer dimensión representa los canales de colores (RGB) y la segunda y tercer dimensión representa la cantidad de píxeles de la imágen. Por ejemplo, si tenemos una imagen a color de 1024x1024 y la convertimos en un tensor, entonces tendríamos un tensor de tres dimensiones con tamaño `torch.Size([3, 1024, 1024])`.*"
   ]
  },
  {
   "cell_type": "code",
   "id": "61226c7f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T23:39:45.017382Z",
     "start_time": "2025-04-27T23:39:45.008694Z"
    }
   },
   "source": [
    "random_image_tensor = torch.rand(size=(3, 1024, 1024))\n",
    "random_image_tensor"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.6666, 0.9811, 0.0874,  ..., 0.0707, 0.6793, 0.9227],\n",
       "         [0.5303, 0.1988, 0.9099,  ..., 0.8482, 0.8240, 0.6414],\n",
       "         [0.6738, 0.6613, 0.5519,  ..., 0.1718, 0.1639, 0.0116],\n",
       "         ...,\n",
       "         [0.2805, 0.7836, 0.6706,  ..., 0.5299, 0.3607, 0.4438],\n",
       "         [0.6341, 0.8021, 0.2384,  ..., 0.7361, 0.5131, 0.0082],\n",
       "         [0.2442, 0.3589, 0.8952,  ..., 0.6155, 0.4215, 0.6004]],\n",
       "\n",
       "        [[0.2620, 0.3809, 0.0809,  ..., 0.1393, 0.5335, 0.1217],\n",
       "         [0.7090, 0.4542, 0.6700,  ..., 0.2559, 0.0658, 0.7274],\n",
       "         [0.7688, 0.7784, 0.5482,  ..., 0.1722, 0.1141, 0.1717],\n",
       "         ...,\n",
       "         [0.5084, 0.3411, 0.4173,  ..., 0.2874, 0.1223, 0.0622],\n",
       "         [0.5953, 0.5328, 0.2545,  ..., 0.2621, 0.1383, 0.2893],\n",
       "         [0.7187, 0.6074, 0.9588,  ..., 0.7932, 0.8076, 0.1934]],\n",
       "\n",
       "        [[0.2462, 0.8442, 0.7218,  ..., 0.8065, 0.4769, 0.2840],\n",
       "         [0.3523, 0.1319, 0.9459,  ..., 0.8241, 0.6992, 0.9141],\n",
       "         [0.9984, 0.4112, 0.9072,  ..., 0.2477, 0.0688, 0.7560],\n",
       "         ...,\n",
       "         [0.0066, 0.9798, 0.0057,  ..., 0.7562, 0.6618, 0.0627],\n",
       "         [0.1364, 0.2482, 0.0803,  ..., 0.0262, 0.5486, 0.5430],\n",
       "         [0.8636, 0.6823, 0.9480,  ..., 0.4555, 0.6629, 0.0179]]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 85
  },
  {
   "cell_type": "code",
   "id": "f68d5df5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T23:39:45.025981Z",
     "start_time": "2025-04-27T23:39:45.024257Z"
    }
   },
   "source": [
    "print(f'Dimensiones: {random_image_tensor.ndim}')\n",
    "print(f'Shape: {random_image_tensor.shape}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones: 3\n",
      "Shape: torch.Size([3, 1024, 1024])\n"
     ]
    }
   ],
   "execution_count": 86
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "*Siempre que trabajemos con procesos aleatorios (o pseudo-aleatorios), vamos a observar diferentes resultados en las ejecuciones. Incluso teniendo la misma semilla, puede que el mismo proceso aleatorio genere distintos resultados si lo ejecutamos en distintos dispositivos (i.e., CPU o GPU). Para más información acerca de como trabajar con procesos no-determinísticos en PyTorch, leer la siguiente [documentación](https://pytorch.org/docs/stable/notes/randomness.html).*\n",
    "\n",
    "*Podemos definir una semilla que nos permita reproducir los resultados de un experimento utilizando la función `torch.manual_seed()` (se define la misma semilla para todos los dispositivos). Ahora, ejecutar multiples veces el mismo código nos devuelve el mismo resultado.*"
   ],
   "id": "77b8b08e558b8e53"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T23:39:45.040371Z",
     "start_time": "2025-04-27T23:39:45.035413Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(42)\n",
    "random_tensor_1 = torch.rand(size=(1, 5))\n",
    "random_tensor_2 = torch.rand(size=(1, 5))\n",
    "\n",
    "print(f'Random tensor 1: {random_tensor_1}')\n",
    "print(f'Random tensor 2: {random_tensor_2}')\n",
    "\n",
    "# We can compare two tensors using the function torch.equal() or the operator ==\n",
    "print(f'Are the tensors equal? {torch.equal(random_tensor_1, random_tensor_2)}')"
   ],
   "id": "9c9dd953aa1bcb2f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random tensor 1: tensor([[0.8823, 0.9150, 0.3829, 0.9593, 0.3904]])\n",
      "Random tensor 2: tensor([[0.6009, 0.2566, 0.7936, 0.9408, 0.1332]])\n",
      "Are the tensors equal? False\n"
     ]
    }
   ],
   "execution_count": 87
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "*Notar que, a pesar de estar utilizando la misma semilla, los tensores que generamos no son iguales. Para obtener dos tensores iguales deberíamos a ejecutar `torch.manual_seed()` antes de crear cada uno de los tensores.*",
   "id": "59c5c870d06425d7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T23:39:45.051173Z",
     "start_time": "2025-04-27T23:39:45.048297Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(42) # Definimos la semilla para el primer tensor\n",
    "random_tensor_1 = torch.rand(size=(1, 5))\n",
    "torch.manual_seed(42) # Definimos la semilla para el segundo tensor\n",
    "random_tensor_2 = torch.rand(size=(1, 5))\n",
    "\n",
    "print(f'Random tensor 1: {random_tensor_1}')\n",
    "print(f'Random tensor 2: {random_tensor_2}')\n",
    "\n",
    "# We can compare two tensors using the function torch.equal() or the operator ==\n",
    "print(f'Are the tensors equal? {torch.equal(random_tensor_1, random_tensor_2)}')"
   ],
   "id": "55962d6e86c71698",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random tensor 1: tensor([[0.8823, 0.9150, 0.3829, 0.9593, 0.3904]])\n",
      "Random tensor 2: tensor([[0.8823, 0.9150, 0.3829, 0.9593, 0.3904]])\n",
      "Are the tensors equal? True\n"
     ]
    }
   ],
   "execution_count": 88
  },
  {
   "cell_type": "markdown",
   "id": "a13f1a17",
   "metadata": {},
   "source": "## Tensor-like objects"
  },
  {
   "cell_type": "code",
   "id": "4a5c4383",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T23:39:45.063633Z",
     "start_time": "2025-04-27T23:39:45.061623Z"
    }
   },
   "source": [
    "range_tensor = torch.arange(start=0, end=1000, step=36)\n",
    "range_tensor"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0,  36,  72, 108, 144, 180, 216, 252, 288, 324, 360, 396, 432, 468,\n",
       "        504, 540, 576, 612, 648, 684, 720, 756, 792, 828, 864, 900, 936, 972])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 89
  },
  {
   "cell_type": "code",
   "id": "00d6d2dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T23:39:45.078109Z",
     "start_time": "2025-04-27T23:39:45.076350Z"
    }
   },
   "source": [
    "print(f'Dimension: {range_tensor.ndim}')\n",
    "print(f'Shape: {range_tensor.shape}')\n",
    "print(f'Dtype: {range_tensor.dtype}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension: 1\n",
      "Shape: torch.Size([28])\n",
      "Dtype: torch.int64\n"
     ]
    }
   ],
   "execution_count": 90
  },
  {
   "cell_type": "markdown",
   "id": "d97fc86a",
   "metadata": {},
   "source": [
    "*Cuando decimos que vamos a crear o que creamos un objeto que es \"tensor-like\", nos referimos a crear un nuevo tensor que tenga la misma dimensión, tamaño y tipo de dato que otro tensor ya existente, pero con otros valores.*\n",
    "\n",
    "*Por ejemplo, podemos creamos un nuevo tensor a partir del tensor `range_tensor` que tenga la misma dimensión, tamaño y tipo de dato, pero que la información que contiene sea distinta (solo tenga ceros).*"
   ]
  },
  {
   "cell_type": "code",
   "id": "3f911467",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T23:39:45.094746Z",
     "start_time": "2025-04-27T23:39:45.092392Z"
    }
   },
   "source": [
    "zeros = torch.zeros_like(input=range_tensor)\n",
    "zeros"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 91
  },
  {
   "cell_type": "code",
   "id": "b77d1008",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T23:39:45.110591Z",
     "start_time": "2025-04-27T23:39:45.108982Z"
    }
   },
   "source": [
    "print(f'Dimension: {zeros.ndim}')\n",
    "print(f'Shape: {zeros.shape}')\n",
    "print(f'Dtype: {zeros.dtype}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension: 1\n",
      "Shape: torch.Size([28])\n",
      "Dtype: torch.int64\n"
     ]
    }
   ],
   "execution_count": 92
  },
  {
   "cell_type": "markdown",
   "id": "33743e580e9500f6",
   "metadata": {},
   "source": "## Atributos de los tensores"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Tipo de dato",
   "id": "2316776f6719ea1a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "*Por default, PyTorch crea los tensores utilizando el tipo de dato `torch.float32`. Sin embargo, hay muchos más tipos de datos [disponibles](https://pytorch.org/docs/stable/tensors.html#data-types), los cuales se diferencian principalmente por la precisión númerica que nos aportan. Por ejemplo, el tipo de dato `torch.float64` tiene mucho más precisión numérica que el tipo de dato `torch.float32` (casi el doble de decimales), pero consume mucho más memoria.*\n",
    "\n",
    "*Podemos definir el tipo de dato que queremos para nuestro tensor utilizando el argumento `dtype`.*"
   ],
   "id": "67031bba"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T23:39:45.128848Z",
     "start_time": "2025-04-27T23:39:45.126713Z"
    }
   },
   "cell_type": "code",
   "source": [
    "TENSOR_0 = torch.tensor([3., 2., 1.], dtype=torch.float64)\n",
    "TENSOR_0"
   ],
   "id": "cfbd0c5152e47f36",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 2., 1.], dtype=torch.float64)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 93
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T23:39:45.145060Z",
     "start_time": "2025-04-27T23:39:45.143126Z"
    }
   },
   "cell_type": "code",
   "source": "TENSOR_0.dtype",
   "id": "45843e9f473bafb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 94
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "*Podemos modificar el tipo de dato utilizando el método `torch.Tensor.type()` o el método `torch.Tensor.to()`. Este último método es el más recomendado, ya que también nos permite modificar otros atributos del tensor.*",
   "id": "207eed92c6d856b6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T23:39:45.158853Z",
     "start_time": "2025-04-27T23:39:45.156861Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Change tensor's datatype\n",
    "TENSOR_1 = TENSOR_0.to(dtype=torch.float16) # or use torch.Tensor.to()\n",
    "TENSOR_1"
   ],
   "id": "4a35ed321e5f5eec",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 2., 1.], dtype=torch.float16)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 95
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "*Cuando realizamos operaciones matemáticas entre dos tensores que tienen tipos de datos distintos, PyTorch utiliza una **regla de promoción** para definir el tipo de dato del tensor resultante (tendrá el tipo de dato con mayor precisión). Por ejemplo, si multiplicamos un tensor con tipo de dato `torch.float32` y otro con tipo de dato `torch.float64`, el tensor que obtenemos después de la operación es `torch.float64`.*\n",
    "\n",
    "*Esto es algo importante a tener en cuenta porque:*\n",
    "1. *Podemos llegar a consumir más memoria de la esperada si las operaciones que realizamos están constantemente incrementando la precisión númerica de nuestros tensores.*\n",
    "2. *Las operaciones entre tensores con distintos tipos de datos suelen ser menos performantes porque PyTorch también se tiene que encargar de convertir los datos.*\n",
    "3. *Algunos dispositivos tienen soporte limitado para algunos tipos de datos (e.g., las GPU no soportan tensores con tipos de datos `torch.float64` o las `mps` no soportan los tensores con tipos de datos `torch.float16`).*"
   ],
   "id": "cea516daba2733c9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T23:39:45.175201Z",
     "start_time": "2025-04-27T23:39:45.172636Z"
    }
   },
   "cell_type": "code",
   "source": "TENSOR_0 * TENSOR_1",
   "id": "125494bc90c63117",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9., 4., 1.], dtype=torch.float64)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 96
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Dispositivo",
   "id": "45ba96f0fa9bfdbf"
  },
  {
   "cell_type": "markdown",
   "id": "f8e63427",
   "metadata": {},
   "source": [
    "*Podemos también definir el **dispositivo** en donde se guarda y ejecuta el tensor. Hay varios tipos de dispositivos que podemos utilizar, pero los más utilizados son:*\n",
    "1. *`cpu`: nos permite guardar y ejecutar los tensores en la memoria RAM de nuestra computadora o máquina virtual.*\n",
    "2. *`cuda`: nos permite guardar y ejecutar los tensores en la GPU. Si tenemos disponibles más de una GPU, podemos especificar cual queremos utilizar, e.g.,  `cuda:0` (primer GPU), `cuda:1` (segunda GPU), `cuda:2` (tercera GPU), etc.*\n",
    "3. *`mps`: nos prmite utilizar la GPU integrada en las computadoras con chips Apple Silicon (similar a como `cuda` nos permite utilizar las GPUs de NVIDIA).*\n",
    "\n",
    "*Por qué es importante definir el dispositivo?:*\n",
    "1. *Si tenemos dos tensores que están guardados en dos dispositivos distintos no podemos realizar operaciones entre ellos.*\n",
    "2. *Si queremos guardar y ejecutar los tensores en la GPU, tenemos que seleccionar el dispositivo `cuda`.*\n",
    "3. *Mover tensores de un dispositivo a otro puede ser computacionalmente costoso.*"
   ]
  },
  {
   "cell_type": "code",
   "id": "65c0aaf5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T23:39:45.189036Z",
     "start_time": "2025-04-27T23:39:45.186744Z"
    }
   },
   "source": [
    "TENSOR.device"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 97
  },
  {
   "cell_type": "markdown",
   "id": "a9ae0318",
   "metadata": {},
   "source": [
    "*Podemos elegir el dispositivo en donde queremos guardar y ejecutar el tensor al momento de crearlo:*"
   ]
  },
  {
   "cell_type": "code",
   "id": "d6e619b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T23:39:45.208869Z",
     "start_time": "2025-04-27T23:39:45.200220Z"
    }
   },
   "source": [
    "# Define a torch.device\n",
    "torch_device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Create a new tensor with specified device\n",
    "TENSOR_2 = torch.rand(size=(3, 1024, 1024), device='cpu')\n",
    "print(f'Tensor: {TENSOR_2}')\n",
    "print(f'Device: {TENSOR_2.device}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor: tensor([[[0.6009, 0.2566, 0.7936,  ..., 0.7124, 0.2065, 0.5760],\n",
      "         [0.1976, 0.7499, 0.2813,  ..., 0.3988, 0.7365, 0.6829],\n",
      "         [0.0499, 0.2046, 0.5168,  ..., 0.3662, 0.0104, 0.4482],\n",
      "         ...,\n",
      "         [0.8996, 0.0490, 0.7916,  ..., 0.8479, 0.9953, 0.1614],\n",
      "         [0.0894, 0.1535, 0.1571,  ..., 0.3873, 0.8991, 0.6478],\n",
      "         [0.0201, 0.3778, 0.1633,  ..., 0.9565, 0.9679, 0.9763]],\n",
      "\n",
      "        [[0.8273, 0.4332, 0.7660,  ..., 0.5370, 0.0109, 0.8638],\n",
      "         [0.0710, 0.9027, 0.1023,  ..., 0.8887, 0.2716, 0.5103],\n",
      "         [0.0258, 0.8463, 0.4397,  ..., 0.2049, 0.7828, 0.2040],\n",
      "         ...,\n",
      "         [0.0307, 0.5348, 0.4726,  ..., 0.1216, 0.4119, 0.9457],\n",
      "         [0.0489, 0.9974, 0.1015,  ..., 0.6457, 0.5405, 0.1967],\n",
      "         [0.7970, 0.3450, 0.1873,  ..., 0.0286, 0.7181, 0.1854]],\n",
      "\n",
      "        [[0.5284, 0.8363, 0.7645,  ..., 0.4472, 0.3017, 0.6413],\n",
      "         [0.6611, 0.7715, 0.3460,  ..., 0.7348, 0.1475, 0.1933],\n",
      "         [0.4940, 0.4051, 0.1993,  ..., 0.4237, 0.1482, 0.7313],\n",
      "         ...,\n",
      "         [0.2588, 0.5405, 0.5456,  ..., 0.5574, 0.6089, 0.0794],\n",
      "         [0.9169, 0.4268, 0.9218,  ..., 0.2596, 0.3913, 0.5813],\n",
      "         [0.8085, 0.0355, 0.8924,  ..., 0.6471, 0.0577, 0.7616]]])\n",
      "Device: cpu\n"
     ]
    }
   ],
   "execution_count": 98
  },
  {
   "cell_type": "markdown",
   "id": "6b87d709",
   "metadata": {},
   "source": [
    "*Podemos también utilizar la función `torch.Tensor.to` para cambiar el tipo de dato o el dispositivo de un tensor (notar que es necesario re-asignar el tensor a la variable):*"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T23:39:45.377901Z",
     "start_time": "2025-04-27T23:39:45.217671Z"
    }
   },
   "cell_type": "code",
   "source": [
    "TENSOR_2 = TENSOR_2.to(device='mps')\n",
    "print(f'Device: {TENSOR_2.device}')"
   ],
   "id": "f6d77296c9425c32",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps:0\n"
     ]
    }
   ],
   "execution_count": 99
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Gradientes",
   "id": "3a232e5b62633ef3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "*Otro argumento importante de los tensores es el argumento `requires_grad`. Cuando definimos `requires_grad=True` en un tensor, le estamos pidiendo a PyTorch que guarde todas las operaciones realizadas sobre ese tensor, para así poder calcular los gradientes. Esto es muy útil cuando queremos entrenar un modelo de Deep Learning, ya que nos permite calcular los gradientes de la función de pérdida con respecto a los pesos del modelo utilizando backpropagation.*\n",
    "\n",
    "*Notar que en el siguiente ejemplo creamos una nueva variable, `y`, que es igual a la suma de los elementos del tensor `X`. Luego, para calcular los gradientes de `y` con respecto a los elementos en `X`, llamamos a la función `.backward()` desde la variable `y`. Sin embargo, los gradientes los podemos encontrar en el tensor `X` (eso tiene sentido porque los gradientes nos dicen como cambia `y` cuando cambia un elemento de `X`.*"
   ],
   "id": "51bdc51199bf470"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T23:39:47.314918Z",
     "start_time": "2025-04-27T23:39:47.218765Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Creates a tensor and operates on it\n",
    "X = torch.tensor([3., 2., 1.], requires_grad=True, device='mps')\n",
    "\n",
    "# Sum all elements of the tensor and compute the gradients\n",
    "y = X.sum()\n",
    "y.backward()\n",
    "print(f'Gradients after automatic differentiation: {TENSOR_0.grad}')"
   ],
   "id": "8d82fb567c1721aa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradients after automatic differentiation: None\n"
     ]
    }
   ],
   "execution_count": 100
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## PyTorch y NumPy\n",
    "\n",
    "*Podemos crear tensores a partir de arrays de NumPy, y viceversa. Esto es muy útil porque podemos utilizar las funcionalidades NumPy para manipular nuestros datos, y luego utilizar los tensores de PyTorch para entrenar nuestros modelos de Deep Learning.*\n",
    "\n",
    "*Podemos crear un tensor a partir de un array de NumPy utilizando la función `torch.from_numpy(ndarray)`. Si queremos convertir un tensor a un array de NumPy, tenemos que utilizar el método `torch.Tensor.numpy()`.*"
   ],
   "id": "994917e34f947c57"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T23:39:48.356454Z",
     "start_time": "2025-04-27T23:39:48.354793Z"
    }
   },
   "cell_type": "code",
   "source": [
    "array = np.arange(1., 10.).reshape((3, 3))\n",
    "print(f'Array de NumPy: \\n{array}')"
   ],
   "id": "9197359ed8de27f6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array de NumPy: \n",
      "[[1. 2. 3.]\n",
      " [4. 5. 6.]\n",
      " [7. 8. 9.]]\n"
     ]
    }
   ],
   "execution_count": 101
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T23:39:48.408631Z",
     "start_time": "2025-04-27T23:39:48.406508Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tensor = torch.from_numpy(array)\n",
    "print(f'Tensor de PyTorch: \\n{tensor}')"
   ],
   "id": "e337249c29cd1375",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor de PyTorch: \n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.],\n",
      "        [7., 8., 9.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "execution_count": 102
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "*Algo muy importante a tener en cuenta es que el tipo de dato predeterminado por NumPy es diferente al de PyTorch (NumPy utiliza `float64` mientras que PyTorch utiliza `float32`). El tensor que creamos a partir del array de NumPy hereda el tipo de dato del array, lo cual podría generar problemas al querer operar entre tensores (si los tipos de datos no coinciden).*",
   "id": "7f1c0471e2713fff"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T23:39:48.446452Z",
     "start_time": "2025-04-27T23:39:48.444333Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"Array's datatype: {array.dtype}\")\n",
    "print(f\"Tensor's datatype: {tensor.dtype}\")"
   ],
   "id": "55f2bdc051f29607",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array's datatype: float64\n",
      "Tensor's datatype: torch.float64\n"
     ]
    }
   ],
   "execution_count": 103
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T23:39:48.482443Z",
     "start_time": "2025-04-27T23:39:48.480362Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tensor = tensor.type(torch.float32)\n",
    "print(f\"Tensor's datatype: {tensor.dtype}\")"
   ],
   "id": "9f8e4f7ea8a36f7a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor's datatype: torch.float32\n"
     ]
    }
   ],
   "execution_count": 104
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T23:39:48.513410Z",
     "start_time": "2025-04-27T23:39:48.512103Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "b23c4d945d9f8939",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
