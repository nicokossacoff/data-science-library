{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score, silhouette_samples, jaccard_score\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "from plotly.subplots import make_subplots\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "from unsupervised_helper_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/usa_arrests.csv')\n",
    "df.columns = ['state'] + list(df.columns.str.lower())[1:]\n",
    "df = df.set_index('state')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculamos los componentes principales para poder graficar los clusters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_model = PCA(n_components=2).fit(df)\n",
    "var = pca_model.explained_variance_ratio_\n",
    "pca = pca_model.transform(df)\n",
    "\n",
    "labels = [f'PC{i+1} ({var[i] * 100:.2f}%)' for i in np.arange(2)]\n",
    "pca = pd.DataFrame(pca, columns=labels, index=df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graficamos las distribuciones de todas las features. A primera vista podemos ver que las variables tienen diferentes escalas, lo que podría generar problemas con el algoritmo, ya que depende de las distancias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = px.box(df, orientation='h')\n",
    "figure.update_layout(\n",
    "    title='Distributions',\n",
    "    title_font=dict(size=16, family='Arial', color='black', weight='bold'),\n",
    "    yaxis=dict(showgrid=True, gridcolor='LightGray', showline=True, linecolor='Black', zeroline=True, zerolinecolor='LightGray'),\n",
    "    xaxis=dict(showgrid=True, gridcolor='LightGray', showline=True, linecolor='Black', zeroline=True, zerolinecolor='LightGray'),\n",
    "    plot_bgcolor='white'\n",
    ")\n",
    "figure.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizamos las variables y miramos las siguientes distribuciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled = StandardScaler().fit_transform(df)\n",
    "df_scaled = pd.DataFrame(df_scaled, columns=df.columns, index=df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = px.box(df_scaled, orientation='h')\n",
    "figure.update_layout(\n",
    "    title='Distributions',\n",
    "    title_font=dict(size=16, family='Arial', color='black', weight='bold'),\n",
    "    yaxis=dict(showgrid=True, gridcolor='LightGray', showline=True, linecolor='Black', zeroline=True, zerolinecolor='LightGray'),\n",
    "    xaxis=dict(showgrid=True, gridcolor='LightGray', showline=True, linecolor='Black', zeroline=True, zerolinecolor='LightGray'),\n",
    "    plot_bgcolor='white'\n",
    ")\n",
    "figure.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 2x2 subplot grid\n",
    "figure = make_subplots(rows=2, cols=2, subplot_titles=df.columns)\n",
    "\n",
    "# Add each density plot to the respective subplot\n",
    "for (i, c) in enumerate(df.columns):\n",
    "    row = i // 2 + 1\n",
    "    col_pos = i % 2 + 1\n",
    "    density = ff.create_distplot([df_scaled[c]], group_labels=[c], show_hist=False)\n",
    "    for trace in density['data']:\n",
    "        figure.add_trace(trace, row=row, col=col_pos)\n",
    "\n",
    "# Update layout\n",
    "figure.update_layout(\n",
    "    title_text='Density Distributions',\n",
    "    showlegend=False,\n",
    "    height=500,\n",
    "    width=1200,\n",
    "    title_font=dict(size=16, family='Arial', color='black', weight='bold'),\n",
    "    plot_bgcolor='white',\n",
    ")\n",
    "\n",
    "# Update x-axis and y-axis for all subplots\n",
    "for i in range(1, 5):\n",
    "    figure.update_xaxes(row=(i+1)//2, col=(i-1)%2 + 1,\n",
    "                        showgrid=True, gridcolor='LightGray',\n",
    "                        showline=True, linecolor='Black',\n",
    "                        zeroline=True, zerolinecolor='LightGray')\n",
    "    figure.update_yaxes(row=(i+1)//2, col=(i-1)%2 + 1,\n",
    "                        showgrid=True, gridcolor='LightGray',\n",
    "                        showline=True, linecolor='Black',\n",
    "                        zeroline=True, zerolinecolor='LightGray')\n",
    "\n",
    "figure.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_scaled = PCA(n_components=2).fit(df_scaled)\n",
    "var = pca_scaled.explained_variance_ratio_\n",
    "pca_scaled = pca_scaled.transform(df_scaled)\n",
    "\n",
    "labels = [f'PC{i+1} ({var[i] * 100:.2f}%)' for i in np.arange(2)]\n",
    "pca_scaled = pd.DataFrame(pca_scaled, columns=labels, index=df_scaled.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajustamos un modelo aglomerativo sin escalar los datos. Para poder graficarlos facilmente en 2D, utilizamos componentes principales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = AgglomerativeClustering(n_clusters=2, linkage='complete')\n",
    "y = tree.fit_predict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = px.scatter(\n",
    "    pca,\n",
    "    x=pca.columns[0],\n",
    "    y=pca.columns[1],\n",
    "    color=y.astype(str),\n",
    "    color_discrete_map={'0': '#E65983', '1': '#2D3846'},\n",
    "    size=[1] * pca.shape[0],\n",
    ")\n",
    "figure.update_layout(\n",
    "    title='Clusters con datos no estandarizados',\n",
    "    title_font=dict(size=16, family='Arial', color='black', weight='bold'),\n",
    "    xaxis_title=pca.columns[0],\n",
    "    yaxis_title=pca.columns[1],\n",
    "    plot_bgcolor='white',\n",
    "    yaxis=dict(showgrid=True, gridcolor='LightGray', showline=True, linecolor='Black', zeroline=True, zerolinecolor='LightGray'),\n",
    "    xaxis=dict(showgrid=True, gridcolor='LightGray', showline=True, linecolor='Black', zeroline=True, zerolinecolor='LightGray'),\n",
    ")\n",
    "figure.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si ajustamos el mismo modelo con los datos estandarizados, obtenemos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_scaled = AgglomerativeClustering(n_clusters=2, linkage='complete')\n",
    "y_scaled = tree_scaled.fit_predict(df_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = px.scatter(\n",
    "    pca_scaled,\n",
    "    x=pca_scaled.columns[0],\n",
    "    y=pca_scaled.columns[1],\n",
    "    color=y_scaled.astype(str),\n",
    "    color_discrete_map={'0': '#E65983', '1': '#2D3846'},\n",
    "    size=[1] * pca.shape[0],\n",
    ")\n",
    "figure.update_layout(\n",
    "    title='Clusters con datos estandarizados',\n",
    "    title_font=dict(size=16, family='Arial', color='black', weight='bold'),\n",
    "    xaxis_title=pca_scaled.columns[0],\n",
    "    yaxis_title=pca_scaled.columns[1],\n",
    "    plot_bgcolor='white',\n",
    "    yaxis=dict(showgrid=True, gridcolor='LightGray', showline=True, linecolor='Black', zeroline=True, zerolinecolor='LightGray'),\n",
    "    xaxis=dict(showgrid=True, gridcolor='LightGray', showline=True, linecolor='Black', zeroline=True, zerolinecolor='LightGray'),\n",
    ")\n",
    "figure.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que los resultados encontrados en ambos casos difieren. Es por eso que, para algoritmos que depedenden de las distancias de las observaciones, como los algoritmos jerárquicos, es mejor normalizar las variables primero.\n",
    "\n",
    "Ya habiendo normalizado los datos, buscamos el valor de $K$ óptimo (i.e., la cantidad óptima de clusters para nuestro problema). Para hacer esto, ajustamos varios modelos con distintos valores de $K$. El valor óptimo es aquel a partir del cual la reducción en la dispersión total intra-grupo comienza a ser más lenta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for k in np.arange(2, 11):\n",
    "    tree = AgglomerativeClustering(n_clusters=k, linkage='complete')\n",
    "    labels = tree.fit_predict(df_scaled)\n",
    "    score = silhouette_score(df_scaled, labels)\n",
    "    scores.append(score)\n",
    "\n",
    "figure = px.line(\n",
    "    x=np.arange(2, 11),\n",
    "    y=scores\n",
    ")\n",
    "figure.update_layout(\n",
    "    title='Elbow Method',\n",
    "    title_font=dict(size=16, family='Arial', color='black', weight='bold'),\n",
    "    xaxis_title='K',\n",
    "    yaxis_title='Silhouette Score',\n",
    "    plot_bgcolor='white',\n",
    "    yaxis=dict(showgrid=True, gridcolor='LightGray', showline=True, linecolor='Black', zeroline=True, zerolinecolor='LightGray'),\n",
    "    xaxis=dict(showgrid=True, gridcolor='LightGray', showline=True, linecolor='Black', zeroline=True, zerolinecolor='LightGray'),\n",
    ")\n",
    "figure.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajustamos el modelo con el número óptimo de clusters: $k=4$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = AgglomerativeClustering(n_clusters=4, linkage='complete')\n",
    "y = tree.fit_predict(df_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = px.scatter(\n",
    "    pca_scaled,\n",
    "    x=pca_scaled.columns[0],\n",
    "    y=pca_scaled.columns[1],\n",
    "    color=y.astype(str),\n",
    "    color_discrete_map={'0': '#E65983', '1': '#4FDFEF', '2': '#3D8791', '3': '#2D3846'},\n",
    "    size=[1] * pca.shape[0],\n",
    ")\n",
    "figure.update_layout(\n",
    "    title='Clusters con datos estandarizados',\n",
    "    title_font=dict(size=16, family='Arial', color='black', weight='bold'),\n",
    "    xaxis_title=pca_scaled.columns[0],\n",
    "    yaxis_title=pca_scaled.columns[1],\n",
    "    plot_bgcolor='white',\n",
    "    yaxis=dict(showgrid=True, gridcolor='LightGray', showline=True, linecolor='Black', zeroline=True, zerolinecolor='LightGray'),\n",
    "    xaxis=dict(showgrid=True, gridcolor='LightGray', showline=True, linecolor='Black', zeroline=True, zerolinecolor='LightGray'),\n",
    ")\n",
    "figure.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Miramos los índices de Silhouette para cada cluster para tener una idea de la cohesión y dispersión de los clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette_values = silhouette_samples(df_scaled, y)\n",
    "\n",
    "n_clusters = len(np.unique(y))\n",
    "y_lower, y_upper = 0, 0\n",
    "yticks = []\n",
    "colors = ['#E65983', '#4FDFEF', '#3D8791', '#2D3846']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "for i in np.arange(n_clusters):\n",
    "    cluster_silhouette_vals = silhouette_values[y == i]\n",
    "    cluster_silhouette_vals.sort()\n",
    "    y_upper += len(cluster_silhouette_vals)\n",
    "    ax.barh(np.arange(y_lower, y_upper), cluster_silhouette_vals, edgecolor='white', height=1, color=colors[i])\n",
    "    yticks.append((y_lower + y_upper) / 2)\n",
    "    y_lower += len(cluster_silhouette_vals)\n",
    "\n",
    "ax.axvline(x=np.mean(silhouette_values), color=\"black\", linestyle=\"--\")\n",
    "ax.set_yticks(yticks, [f'Cluster {i}' for i in np.arange(n_clusters)])\n",
    "ax.set_xlabel('Silhouette Coefficient')\n",
    "ax.set_title('Silhouette Plot', loc='left', fontdict={'fontsize': 16, 'fontweight': 'bold'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descartamos ahora a la variable `UrbanPop` del análisis. Primero buscamos el número óptimo de clusters para el problema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled_new = df_scaled.loc[:, df_scaled.columns != 'urbanpop']\n",
    "\n",
    "scores = []\n",
    "for k in np.arange(2, 11):\n",
    "    tree = AgglomerativeClustering(n_clusters=k, linkage='complete')\n",
    "    labels = tree.fit_predict(df_scaled_new)\n",
    "    score = silhouette_score(df_scaled_new, labels)\n",
    "    scores.append(score)\n",
    "\n",
    "figure = px.line(\n",
    "    x=np.arange(2, 11),\n",
    "    y=scores\n",
    ")\n",
    "figure.update_layout(\n",
    "    title='Elbow Method',\n",
    "    title_font=dict(size=16, family='Arial', color='black', weight='bold'),\n",
    "    xaxis_title='K',\n",
    "    yaxis_title='Silhouette Score',\n",
    "    plot_bgcolor='white',\n",
    "    yaxis=dict(showgrid=True, gridcolor='LightGray', showline=True, linecolor='Black', zeroline=True, zerolinecolor='LightGray'),\n",
    "    xaxis=dict(showgrid=True, gridcolor='LightGray', showline=True, linecolor='Black', zeroline=True, zerolinecolor='LightGray'),\n",
    ")\n",
    "figure.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_scaled_new = PCA(n_components=2).fit(df_scaled_new)\n",
    "pca_scaled_new = pca_scaled_new.transform(df_scaled_new)\n",
    "pca_scaled_new = pd.DataFrame(pca_scaled_new, columns=['PC1', 'PC2'], index=df_scaled_new.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_new = AgglomerativeClustering(n_clusters=4, linkage='complete')\n",
    "y_new = tree_new.fit_predict(df_scaled_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = px.scatter(\n",
    "    pca_scaled_new,\n",
    "    x='PC1',\n",
    "    y='PC2',\n",
    "    color=y_new.astype(str),\n",
    "    color_discrete_map={'0': '#E65983', '1': '#4FDFEF', '2': '#3D8791', '3': '#2D3846'},\n",
    "    size=[1] * pca_scaled_new.shape[0],\n",
    ")\n",
    "figure.update_layout(\n",
    "    title='Clusters con datos estandarizados',\n",
    "    title_font=dict(size=16, family='Arial', color='black', weight='bold'),\n",
    "    xaxis_title='PC1',\n",
    "    yaxis_title='PC2',\n",
    "    plot_bgcolor='white',\n",
    "    yaxis=dict(showgrid=True, gridcolor='LightGray', showline=True, linecolor='Black', zeroline=True, zerolinecolor='LightGray'),\n",
    "    xaxis=dict(showgrid=True, gridcolor='LightGray', showline=True, linecolor='Black', zeroline=True, zerolinecolor='LightGray'),\n",
    ")\n",
    "figure.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Miramos los índices de Silhouette para cada nuevo cluster para tener una idea de su cohesión y dispersión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette_values = silhouette_samples(df_scaled_new, y)\n",
    "\n",
    "n_clusters = len(np.unique(y))\n",
    "y_lower, y_upper = 0, 0\n",
    "yticks = []\n",
    "colors = ['#E65983', '#4FDFEF', '#3D8791', '#2D3846']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "for i in np.arange(n_clusters):\n",
    "    cluster_silhouette_vals = silhouette_values[y == i]\n",
    "    cluster_silhouette_vals.sort()\n",
    "    y_upper += len(cluster_silhouette_vals)\n",
    "    ax.barh(np.arange(y_lower, y_upper), cluster_silhouette_vals, edgecolor='white', height=1, color=colors[i])\n",
    "    yticks.append((y_lower + y_upper) / 2)\n",
    "    y_lower += len(cluster_silhouette_vals)\n",
    "\n",
    "ax.axvline(x=np.mean(silhouette_values), color=\"black\", linestyle=\"--\")\n",
    "ax.set_yticks(yticks, [f'Cluster {i}' for i in np.arange(n_clusters)])\n",
    "ax.set_xlabel('Silhouette Coefficient')\n",
    "ax.set_title('Silhouette Plot', loc='left', fontdict={'fontsize': 16, 'fontweight': 'bold'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 2\n",
    "\n",
    "Utilizar un método de cluster jerárquico para el conjunto de datos `mall_costumers.csv`. Las descripción de las variables y el contexto del problema se pueden encontrar en [Kaggle](https://www.kaggle.com/datasets/vjchoudhary7/customer-segmentation-tutorial-in-python). Probar el método divisivo DIANA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/mall_costumers.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Miramos primero que no hayana datos nulos. En caso de encontrar datos nulos, tenemos que buscar algún metodo de imputación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para la variable categórica `Gender`, vamos a utilizar el método 'binary encoding' para convertirla en una variable numérica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Gender'] = (df['Gender']  == 'Male').astype(int)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Miramos las distribuciones de las variables. Vamos a tener que normalizar los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = px.box(df.iloc[:, 1:], orientation='h')\n",
    "figure.update_layout(\n",
    "    title='Distributions',\n",
    "    title_font=dict(size=16, family='Arial', color='black', weight='bold'),\n",
    "    yaxis=dict(showgrid=True, gridcolor='LightGray', showline=True, linecolor='Black', zeroline=True, zerolinecolor='LightGray'),\n",
    "    xaxis=dict(showgrid=True, gridcolor='LightGray', showline=True, linecolor='Black', zeroline=True, zerolinecolor='LightGray'),\n",
    "    plot_bgcolor='white'\n",
    ")\n",
    "figure.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled = StandardScaler().fit_transform(df.iloc[:, 1:])\n",
    "df_scaled = pd.DataFrame(df_scaled, columns=df.columns[1:], index=df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 2x2 subplot grid\n",
    "figure = make_subplots(rows=2, cols=2, subplot_titles=df_scaled.columns)\n",
    "\n",
    "# Add each density plot to the respective subplot\n",
    "for (i, c) in enumerate(df_scaled.columns):\n",
    "    row = i // 2 + 1\n",
    "    col_pos = i % 2 + 1\n",
    "    density = ff.create_distplot([df_scaled[c]], group_labels=[c], show_hist=False)\n",
    "    for trace in density['data']:\n",
    "        figure.add_trace(trace, row=row, col=col_pos)\n",
    "\n",
    "# Update layout\n",
    "figure.update_layout(\n",
    "    title_text='Density Distributions',\n",
    "    showlegend=False,\n",
    "    height=500,\n",
    "    width=1200,\n",
    "    title_font=dict(size=16, family='Arial', color='black', weight='bold'),\n",
    "    plot_bgcolor='white',\n",
    ")\n",
    "\n",
    "# Update x-axis and y-axis for all subplots\n",
    "for i in range(1, 5):\n",
    "    figure.update_xaxes(row=(i+1)//2, col=(i-1)%2 + 1,\n",
    "                        showgrid=True, gridcolor='LightGray',\n",
    "                        showline=True, linecolor='Black',\n",
    "                        zeroline=True, zerolinecolor='LightGray')\n",
    "    figure.update_yaxes(row=(i+1)//2, col=(i-1)%2 + 1,\n",
    "                        showgrid=True, gridcolor='LightGray',\n",
    "                        showline=True, linecolor='Black',\n",
    "                        zeroline=True, zerolinecolor='LightGray')\n",
    "\n",
    "figure.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2).fit(df_scaled)\n",
    "pca = pca.transform(df_scaled)\n",
    "pca = pd.DataFrame(pca, columns=['PC1', 'PC2'], index=df_scaled.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo\n",
    "\n",
    "Antes de ajustar el modelo, vamos a calcular la cantidad de clusters óptima para este problema. Para eso utilizamos el método de Mean-Max Silhouette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for k in np.arange(2, 11):\n",
    "    tree = AgglomerativeClustering(n_clusters=k, linkage='complete')\n",
    "    labels = tree.fit_predict(df_scaled.iloc[:, 1:])\n",
    "    score = silhouette_score(df_scaled.iloc[:, 1:], labels)\n",
    "    scores.append(score)\n",
    "\n",
    "figure = px.line(\n",
    "    x=np.arange(2, 11),\n",
    "    y=scores\n",
    ")\n",
    "figure.update_layout(\n",
    "    title='Elbow Method',\n",
    "    title_font=dict(size=16, family='Arial', color='black', weight='bold'),\n",
    "    xaxis_title='K',\n",
    "    yaxis_title='Silhouette Score',\n",
    "    plot_bgcolor='white',\n",
    "    yaxis=dict(showgrid=True, gridcolor='LightGray', showline=True, linecolor='Black', zeroline=True, zerolinecolor='LightGray'),\n",
    "    xaxis=dict(showgrid=True, gridcolor='LightGray', showline=True, linecolor='Black', zeroline=True, zerolinecolor='LightGray'),\n",
    ")\n",
    "figure.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = AgglomerativeClustering(n_clusters=5, linkage='complete')\n",
    "y = tree.fit_predict(pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_clusters(data=pca, labels=y, title='Clusters with Agglomerative Clustering')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = px.scatter(\n",
    "    pca,\n",
    "    x='PC1',\n",
    "    y='PC2',\n",
    "    color=y.astype(str),\n",
    "    color_discrete_map={'0': '#E65983', '1': '#2D3846'},\n",
    "    size=[1] * pca.shape[0],\n",
    ")\n",
    "figure.update_layout(\n",
    "    title='Clusters con datos estandarizados',\n",
    "    title_font=dict(size=16, family='Arial', color='black', weight='bold'),\n",
    "    xaxis_title='PC1',\n",
    "    yaxis_title='PC2',\n",
    "    plot_bgcolor='white',\n",
    "    yaxis=dict(showgrid=True, gridcolor='LightGray', showline=True, linecolor='Black', zeroline=True, zerolinecolor='LightGray'),\n",
    "    xaxis=dict(showgrid=True, gridcolor='LightGray', showline=True, linecolor='Black', zeroline=True, zerolinecolor='LightGray'),\n",
    ")\n",
    "figure.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
